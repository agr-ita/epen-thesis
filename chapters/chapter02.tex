%%%%%%%%%%
% [TODO] %
%%%%%%%%%%
% - [ ] mini-intro & general
% --- [ ] No anti-Pinker ...
% --- [ ] Make figures be in logical places
% --- [ ] Add acknowledgements for each paper at the beginning + signal what changed
% - [ ] /ahpa/
% --- [ ] Explain more by speaker figure? (also, change labels to "Dutch stimuli")
% --- [ ] Cluster acoustic analyses:
% ------ [ ] Explain more what is happening visually
% ------ [ ] Is a classifier (eg with LDA) better at labeling coart in /hp/ than in /kp/
% --- [ ] Add contributions (e.g., Isa's ABX)
% --- [ ] ABX
% ------ [ ] Figure: use same order as in table
% ------ [ ] Why? Recall expectations if COART/COPY/DEFAULT-NONE => not sensitive enough for COART vs COPY, but correlation is useful to solidify ID results
% - [ ] Parlato
% --- [ ] Figures
% ------ [X] Change order of V1/V2 in parlato heatmaps
% ------ [X] Add "human"/"model" labels above graphs
% ------ [ ] 

%%%%%%%%%%%%%%%%%%%%%%
% Chapter mini-intro %
%%%%%%%%%%%%%%%%%%%%%%

%% Short background %%

{\color{blue}
While there seems to be a consensus concerning the presence of perceptual misperceptions due to discrepancies between native phonotactics and non-native phoneme structures, the mechanisms underlying these phenomena are subject to more debate. In the case of perceptual (vowel) epenthesis, certain proposals (e.g., \cite{berent2007, monahan2009}) hypothesize that the process is constituted of two steps in which the quality of the epenthetic vowel is determined by a language-specific grammar after an initial parsing. In particular, good candidate vowels might be those that are subject to vowel reduction or deletion in the native language.  
In contrast, one-step proposals (e.g., \cite{dupoux2011}) argue that the identity of the epenthetic vowel is determined in the process of parsing the input. In particular, parsing becomes an optimisation problem where the optimal output is the one maximising the acoustic match to the input and the likelihood of the phonemic sequence in the native language. Results by \cite{dupoux2011} support one-step theories, as they were able to modulate the identity of the epenthetic vowel without changing the segmental structure of the input stimuli. \\

%% Research questions %%
\cite{dupoux2011} manipulated acoustic details in their stimuli, which led to the conclusion that coarticulation cues influenced epenthetic vowel quality. However, several question remain: How does this influence compare to other influences such as those of an abstract grammar? Can we reproduce these modulations of epenthetic vowel quality on naturally produced stimuli? And finally, if acoustics are quintessential to choosing epenthetic vowel quality, does this mean that they are sufficient to do so? \\

%% Plan %%
In \textbf{section \ref{2-ahpa}} a perceptual experiment aims to disentangle the contributions of phonetic categories and acoustic details on epenthetic vowel quality. Participants are asked to report their choice of epenthetic vowel (if any) within consonant clusters in stimuli where the acoustic information contained in the cluster may be in disagreement with the identity of neighbouring vowels. Information theoretic measures allow to quantify the influence of both neighbouring phonetic categories and acoustic details.  \\


In \textbf{section \ref{2-parlato}} I investigate the possibility of predicting epenthetic vowel quality in Brazilian Portuguese (BP) and Japanese (JP) using a production-based exemplar model of perception. This type of model predicts the quality of a vowel epenthesized within the cluster of a stimulus based solely on the acoustic similarity of said /CC/ cluster to /CVC/ exemplars produced by native speakers of BP or JP. From this modelling approach we can evaluate the influence of pure acoustics on effects such as default epenthetic vowel quality and modulations induced by neighbouring vowels, with naturally produced stimuli that have not been manipulated.}

%%%%%%%%%%%%%%%%%%%%
% /ahpa/ (JASA-EL) %
%%%%%%%%%%%%%%%%%%%%

%%%% Main %%%%
% \includepdf[pages={2-8}, pagecommand={},
% addtotoc={
%   2,section,1,Which epenthetic vowel? \\ Phonetic categories versus acoustic detail in perceptual vowel epenthesis,ahpa_main,
%   3,subsection,2,Methods,ahpa_methods,
%   4,subsection,2,Results,ahpa_results,
%   6,subsection,2,Discussion,ahpa_disc,
%   7,subsection,2,References,ahpa_ref}]
% {images/chapter02/JASAEL_Guevara-Rukoz_2017_Which_epenthetic_vowel.pdf}

\newpage
\section{Which epenthetic vowel? \\ Phonetic categories versus acoustic detail in perceptual vowel epenthesis} \label{2-ahpa}

%[TODO] Say that this is a modified version of the JASA-EL paper

\textit{{\color{blue}The following section is a modified version of the following journal article: \\
Guevara-Rukoz, A., Lin, I., Morii, M., Minagawa, Y., Dupoux, E., \& Peperkamp, S. (2017). Which epenthetic vowel? Phonetic categories versus acoustic detail in perceptual vowel epenthesis. The Journal of the Acoustical Society of America, 142(2), EL211-EL217.}}

\paragraph{Abstract}

This study aims to quantify the relative contributions of phonetic categories and acoustic detail on phonotactically-induced perceptual vowel epenthesis in Japanese listeners. A vowel identification task tested whether a vowel was perceived within illegal consonant clusters and, if so, which vowel was heard. Cross-spliced stimuli were used in which vowel coarticulation present in the cluster did not match the quality of the flanking vowel. Two clusters were used, /hp/ and /kp/, the former containing larger amounts of resonances of the preceding vowel. While both flanking vowel and coarticulation influenced vowel quality, the influence of coarticulation was larger, especially for /hp/.

\subsection{Introduction}
% \label{sec:Introduction}

\setlength{\parindent}{5ex}

Our auditory perceptual system is tuned to the sound system of our native language, resulting in impoverished perception of nonnative sounds and sound sequences \cite{sebastian2005}. For instance, in Japanese, a vowel can only be followed by a moraic nasal consonant or by a geminate consonant. As a consequence, Japanese listeners tend to perceive an illusory, epenthetic, \textipa{/u/} within illegal consonant clusters \cite{dupoux1999, dehaene2000, dupoux2001, monahan2009, dupoux2011, guekozIS17} and it is evident in loanword adaptation as well (e.g. the word 'sphynx' is borrowed in Japanese as /sufiNkusu/). Similar effects have been documented in other languages, with different epenthetic vowels (\textipa{/1/} in Korean \cite{kabak2007, berent2008, dejong2012}; schwa in English \cite{berent2007, davidson2012}; /i/ in Brazilian Portuguese \cite{dupoux2011, guekozIS17}; and /e/ in Spanish \cite{halle2014}). Even within languages, there sometimes is variation in the quality of the epenthetic vowel; for instance, in Japanese, the epenthetic vowel can in certain contexts be \textipa{/i/} or \textipa{/o/} \cite{mattingley2015, guekozIS17}.

The factors that determine the quality of the epenthetic vowel are still unclear. There is evidence that local acoustic cues in the form of vowel coarticulation play a role. Specifically, using artificial consonant clusters obtained by completely removing an inter-consonantal vowel, \cite{dupoux2011} found that the quality of the removed vowel -- traces of which are present in the neighboring consonants -- influences the quality of the epenthetic vowel. Other studies, however, have argued for an influence of phonological factors, such as the legality of the resulting repair at the phonotactic level \cite{mattingley2015} or the presence of phonological alternations in the language \cite{durvasula2015}. Determining the source of epenthetic vowel quality is important at a theoretical level, because it can shed light on the computational mechanisms underlying the perception of speech sounds. For instance, \cite{dupoux2011} argued that coarticulation effects cannot be accounted for by two-step models, in which the repair of illegal sequences follows that of phoneme categorization, while they are in accordance with one-step models, in which phoneme categorization takes phonotactic probabilities into account.
\footnote{Note that due to a typo the summary in the first-to-last paragraph of this article erroneously states the opposite.} 
However, \cite{dupoux2011} only assessed the presence of acoustic effects, without investigating a possible role of categorical effects. Here, our aim is to quantify the relative contributions of categorical and acoustic effects on epenthetic vowel quality by directly comparing these two types of effect. 

We focus on perceptual vowel epenthesis following \textipa{/h/}. This case is ideally suited for our objective as in Japanese loanwords these fricatives are typically adapted by adding a `copy' of the preceding vowel when they occur in a syllable coda. For instance, \textit{`Bach'}, \textit{`(van) Gogh'}, and \textit{`Ich-Roman'} are adapted as \textipa{/bah:a/}, \textipa{/goh:o/}, and \textipa{/ih:iroman/}. In work on loanword adaptations, cases of vowel copy in epenthesis have been explained as a result of the spreading of phonological features from the preceding vowel onto the epenthetic vowel (i.e., vowel harmony), for instance in Shona, Sranan, and Samoan \cite{uffmann2006}, and Sesotho \cite{rose2006}. In speech perception, however, this pattern could be based either on phonetic categories, i.e. the preceding vowel itself, or on acoustic detail, i.e. traces of this vowel that are present in /h/, as laryngeal fricatives such as \textipa{/h/} contain acoustic information relative to formants of surrounding vowels \cite{keating1988}. Using an identification task, we tease apart these two explanations by independently manipulating the categorical context in which \textipa{/h/} occurs and the acoustic realization of this segment, using cross-splicing. As a control, we also use stimuli with \textipa{/k/}, which are expected to give rise to more default \textipa{/u/}-epenthesis because they contain less coarticulation. 

\subsection{Methods}

\subsubsection{\textit{Participants}}
%\label{ssec:subj}

Twenty-five native Japanese speakers were tested in Tokyo, Japan (mean age $24 \pm 3.5$; 13 female). All were students at Keio University, and none had lived abroad. 

\subsubsection{\textit{Stimuli}}
%\label{ssec:stim}

We constructed a set of 20 base items, 10 disyllabic ones of the form $V_{1}C_{1}C_{2}V_{1}$ and 10 matched trisyllabic ones of the form $V_{1}C_{1}V_{1}C_{2}V_{1}$, 
with $V_{1}$ a vowel in the set \textipa{/a, e, i, o, u/} (henceforth: flanking vowel), $C_{1}$ \textipa{/h/} or /k/, and $C_{2}$ a fixed consonant, /p/, e.g. \textipa{/ahpa/}, \textipa{/ekpe/, /ohopo/, /ikipi/}. Three trained phoneticians, native speakers of Dutch, American English and Argentinian Spanish, respectively, recorded all items with stress on the first syllable. All /kp/ stimuli presented release bursts. For each disyllabic item, we used one token per speaker as a natural control stimulus. By systematically replacing the $/C_{1}C_{2}/$-cluster in these items by the same cluster out of the other disyllabic items produced by the same speaker but with a different vowel, we created spliced test stimuli such as $/ah_{o}pa/$, and $/ek_{i}pe/$, where the small vowel denotes vowel coarticulation present in the consonant cluster. Similarly, by replacing the $/C_{1}C_{2}/$-cluster in the disyllabic items by the same cluster out of the second token of the same items, we created spliced control stimuli in which the vowel coarticulation matched the flanking vowel, e.g. $/ah_{a}pa/$, $/ek_{e}pe/$. We also created trisyllabic fillers in which the middle vowel either matched or mismatched the flanking vowel, e.g. \textipa{/ahapa/}, \textipa{/ekepe/}, \textipa{/ahopa/}, \textipa{/ekipe/} (these were also created by splicing, as they served as test stimuli in an experiment not reported in this article). Overall, each speaker thus contributed 40 test stimuli (5 flanking vowels x 4 vowel coarticulations x 2 consonant clusters), 20 control stimuli (5 flanking vowels x 2 consonant clusters, all both in a natural and a spliced form), and 50 fillers. Ten additional training items were recorded by a fourth speaker. Their structure was similar, but included only phonotactically legal nasal + stop sequences with or without an intervening copy vowel (e.g., \textipa{/ampa/, /enepe/}). 

\subsubsection{\textit{Procedure}}
%\label{ssec:procedure}

Participants were tested individually in a soundproof room. At each trial, they heard a stimulus over headphones and were asked to identify the vowel between the two consonants, if any. They were provided with a transcription of the item on screen, containing a question mark between the two consonants (e.g. \textit{``ah?pa"}) in latin characters (as non-CV syllables cannot be transcribed using Japanese characters), as well as the list of possible responses: \textit{``none, a, i, u, e, o"}. Participants responded by pressing labelled keys on a keyboard. Participants were familiarised with the procedure with 10 training trials in which they received on-screen feedback. 

The 330 stimuli were presented in a pseudo-randomised order: Consecutive stimuli were produced by different speakers, and a stimulus could not be followed by a stimulus with the same combination of vowel coarticulation and consonant. Trials were presented in two blocks, with each stimulus appearing once per block, for a total of 660 trials. The experiment lasted approximately 40 minutes. 

\subsection{Results}
%\label{sec:results}

Test and control trials with responses that were either too fast (before the medial portion of the stimulus could be perceived and processed, $<$400 ms) or too slow ($>$ 3 SD: 3238 ms) were excluded from the analyses. This concerned 736 trials (4.5\%).

\subsubsection{\textit{Control items}}
% \label{ssec:ctrl_items}

Participants experienced perceptual epenthesis in 57\% of control items in which the flanking vowel and coarticulation are of the same quality (/hp/: 52\%, /kp/: 61\%). Recall that in loanwords, the default epenthetic vowel is /u/, while after voiceless laryngeal fricatives it is a copy of the preceding vowel. Focusing on trials with an epenthetic response, we examined whether the choice of epenthetic vowel reflected this pattern.

\begin{figure}[H]
  \centering
  \begin{overpic}[page=1, width=0.45\linewidth]{chapter02/ahpa_uep-copyep}\end{overpic}
  \hspace{0.5cm}
  \begin{overpic}[page=2, width=0.45\linewidth]{chapter02/ahpa_uep-copyep}\end{overpic}
  \caption{{\color{blue}\textit{Percentage of default /u/-epenthesis (left) and vowel copy epenthesis (right) for control items. Box plots display the distribution of the scores across speakers (median, quartiles and extrema), with gray lines connecting data points corresponding to a single participant.}}}
  \label{fig:ahpa_uep-copyep}
\end{figure}

First, a generalised mixed-effects model with a declared binomial distribution \cite{R-lme4} was used to examine a possible effect of consonant cluster on default /u/-epenthesis. Thus, we analyzed the proportion of default \textipa{/u/}, using participant, speaker, experimental block, and trial as random effects, and consonant cluster (\textipa{/kp/} \textit{vs.} \textipa{/hp/}; contrast coded) as fixed effect. This model was compared to a reduced model with no fixed effect. The full model was found to explain significantly more variance than the reduced model ($\beta = -4.2$, $SE = 1.2$, $\chi^{2}(1) = 9.9$, $p < 0.01$), showing that participants experienced significantly less default /u/-epenthesis in \textipa{/hp/-} than \textipa{/kp/-}items (39\% \textit{vs.} 86\% of all trials with epenthesis, respectively). 

Next, we examined whether epenthesized vowels shared the quality of the flanking vowel more often in /hp/- than in /kp/-clusters. Given that for items with flanking vowel /u/ it is impossible to know if /u/-epenthesis is due to vowel copy or to default epenthesis, these items were excluded. As before, a generalised mixed-effects model with a declared binomial distribution was used. We analyzed the proportion of vowel copy (i.e., whether the flanking vowel and epenthetic vowel shared quality), using participant, speaker, experimental block, and trial as random effects, and consonant cluster (\textipa{/kp/} \textit{vs.} \textipa{/hp/}; contrast coded) as fixed effect. Comparing this full model to a reduced model with no fixed effects revealed a significant effect of consonant cluster ($\beta = 3.7$, $SE = 1.2$, $\chi^{2}(1) = 7.4$, $p < 0.01$). Therefore, participants epenthesized a vowel that matched the flanking vowel more often in /hp/-clusters (53\%) than in /kp/- clusters (13\%). 

Thus, analysis of control items revealed that, similarly to the loanword pattern, participants perceived the vowel /u/ more often in /kp/- than in /hp/-clusters, and they perceived a vowel copy more often in /hp/- than in /kp/-clusters.

\subsubsection{\textit{Test items}}
\label{ssec:test_items}

\begin{figure}[t!]
\centering
    \centerline{\begin{overpic}[page=1, width=0.9\linewidth]{chapter02/ahpa_tiles.pdf}\end{overpic}}
    \caption {{\it Counts of responses for the test items and spliced control items. Top: \textipa{/hp/-}items; bottom: \textipa{/kp/-}items. Within each rectangle, flanking vowels and vowel coarticulation are given in the horizontal and vertical axes, respectively. Darker colours indicate higher counts. {\color{blue}Figure \ref{fig:ahpa_spk} shows counts separated by speaker}}}
% A figure showing counts separated by speaker can be found in the supplementary materials at https://osf.io/y9h6c}}
\label{fig:tiles}
\end{figure}

Figure \ref{fig:tiles} shows trial counts, separated according to response category, consonant cluster, flanking vowel, and vowel coarticulation for test and control trials. Within the individual rectangles, vertical lines are indicative of a larger influence of flanking vowels compared to vowel coarticulation. Horizontal lines, by contrast, are indicative of a larger influence of vowel coarticulation. Finally, uniform colouring indicates that neither flanking vowels nor vowel coarticulation have the upper hand in influencing the quality of the epenthetic vowel. Note that except for the rectangles with ``none" and ``u" responses where colouring is more uniform, horizontal lines are more visually prominent than vertical lines. Thus, the epenthetic vowel's quality generally depends mostly on acoustic details present in the consonant cluster. 

Focusing on the test trials eliciting epenthesis (/hp/: 62\%, /kp/: 66\%), we quantify the respective influence of flanking vowel and vowel coarticulation (explanatory variables, EV) on the epenthetic vowel (response variable, RV), using two measures from information theory, \textbf{mutual information} (MI) and \textbf{information gain} (IG) \cite[see][for a comprehensive description of these measures]{daland2015}. MI and IG are derived from \textbf{entropy}, which is the `uncertainty' in the value of a RV at a given trial. The lower the entropy $H[X]$ of a variable $X$, the easier it is to predict the outcome of a trial. The \textbf{MI $I[X;Y]$} of variables $X$ and $Y$ represents the reduction in `uncertainty' of the trial outcome for RV $X$, given that the value of EV $Y$ is known (and vice versa). This corresponds to the maximum amount of influence that $Y$ can have over $X$, without removing contributions from other variables. \textbf{IG $H[X|Z] - H[X|Y,Z]$} represents the minimum amount of influence of variable $Y$ on $X$. This corresponds to the reduction in uncertainty as to the value of $X$ that arises from knowing the value of $Y$, after removing all uncertainty explained by variable $Z$. 

As in \cite{daland2015}, we compute \textbf{accidental information} introduced to MI and IG, which corresponds to inaccuracies introduced to our measurements by the process of inferring underlying probability distributions from samples, i.e., sampling error (as when one does not obtain 50 tails and 50 heads when flipping a fair coin 100 times).
We can estimate the accidental information by recomputing MI and IG after having removed the dependencies between the EV and the RV. We can do so by shuffling the values of the EV within each participant. For instance, in order to compute the accidental information introduced to MI and IG for the EV ``vowel coarticulation'', we randomly shuffle the vowel coarticulation labels of all of our trials, per participant, while leaving the EV ``flanking vowel'' untouched. We then compute MI and IG as for the real data. In order to obtain a better estimate of accidental information from an average value, we do this 1000 times (i.e., Monte Carlo shuffling process). 

To recapitulate, for both coarticulation vowel and flanking vowel, we compute `sample' and `accidental' MI and IG. The `true' values of these measures are obtained by removing mean accidental information from sample information. Following \cite{daland2015}, we consider the set of shuffled datasets (i.e., `accidental' MI and IG) as probability distributions given by the null hypotheses that neither coarticulation nor the flanking vowel influence the responses. 

\begin{table}[h!]
\setlength{\tabcolsep}{2pt}
\centering
    \begin{threeparttable}
    \caption{\textit{Quantified influence of vowel coarticulation and flanking vowel on vowel epenthesis measured with information gain (IG) and mutual information (MI). Ranges for Monte Carlo simulations of the null hypothesis (i.e. accidental information) are given in square brackets. Values are given in bits.}} 
    
    \label{infoth}
    \begin{tabular}{lcccccccc}
        \toprule
             & \multicolumn{4}{c}{Vowel coarticulation} & \multicolumn{4}{c}{Flanking vowel} \\ [0.5ex]
             & \multicolumn{2}{c}{IG} & \multicolumn{2}{c}{MI} & \multicolumn{2}{c}{IG} & \multicolumn{2}{c}{MI} \\ \cmidrule(lr){2-3}\cmidrule(lr){4-5} \cmidrule(lr){6-7}\cmidrule(lr){8-9}   
             & data & null & data & null &  data & null &  data & null  \\
        \midrule
             /hp/ & \textbf{$.90$} & $.04$ $[.02,.05]$  & \textbf{$.93$} & $.01$ $[0,.02]$& \textbf{$.07$} & $.03$ $[.02,.05]$ & \textbf{$.09$} & $.01$  $[0,.02]$  \\  %\cline{2-13}
             /kp/ & \textbf{$.47$} & $.03$  $[.02,.05]$ & \textbf{$.53$} & $.01$ $[0,.02]$& \textbf{$.07$} & $.03$ $[.02,.04]$& \textbf{$.13$} & $.01$ $[0,.02]$  \\
    \bottomrule
    \end{tabular}
  \end{threeparttable}
\end{table}

As shown in Table \ref{infoth}, all sample lower bounds are greater than their respective accidental information gains on all 1000 shufflings, for which the ranges are given in parentheses. Therefore, the `true' lower bounds for both coarticulation and flanking vowel influence on epenthesis are greater than $0$ with $p<0.001$, showing that both coarticulation and flanking vowel quality influence participant responses. However, the amount of influence differs greatly: a larger information gain is yielded by considering vowel coarticulation  %29- and 11-times
than by considering the flanking vowel. This is true both for /hp/-items, which are heavily coarticulated, and for /kp/-items, where coarticulation is mainly only present in the burst, even though the influence of coarticulation on epenthetic vowel quality is higher for the former (/hp/: $[0.86, 0.92]$ \textit{vs.} /kp/: $[0.44, 0.52]$). (The range of variation within shuffles of accidental information was about .03; thus any difference of .06 or bigger is significant, including differences between MI and IG values, respectively). In summary, both vowel coarticulation and the flanking vowel influence epenthetic vowel quality, but this influence is greater for vowel coarticulation; response patterns are more predictable when the value of this variable is known than when the value of the flanking vowel variable is known.

\subsection{Discussion and conclusion}
%\label{sec:concl}

We used an identification task to assess the quality of epenthetic vowels perceived by Japanese listeners in illegal consonant clusters with varying amounts of coarticulation. Our findings can be summarized as follows: First, we were able to replicate the perception of illusory vowels within phonotactically illegal clusters by Japanese listeners (64\% of all test trials).\footnote{Note that whereas previous studies examined perceptual epenthesis within clusters with at least one voiced consonant, we presently focused on completely voiceless clusters, a context in which the high vowels /i/ and /u/ may be devoiced in Japanese \cite{han1962, vance1987}}\footnote{As pointed out by an anonymous reviewer, the differences in rates of epenthesis by speaker (Dutch: 68\%, Am. English: 58\%, Arg. Spanish: 66\%) are consistent with an important role for acoustic factors in epenthesis, suggesting that participants interpret speakers' acoustic cues instead of responding based on abstract phonological categories \cite[cf.][]{wilson2014}.{\color{blue}This can also be seen in more detail when decomposing Figure \ref{fig:tiles} by speaker, as in Figure \ref{fig:ahpa_spk}}} %This can also be seen in more detail when decomposing Figure \ref{fig:tiles} by speaker, as in supplementary materials available from https://osf.io/y9h6c}
Second, when the flanking vowel and coarticulation match, the quality of the perceived vowel patterned in the same way as in loanword adaptation data. That is, for \textipa{/kp/}-clusters, the predominant epenthetic vowel was the standard default vowel for Japanese (\textipa{/u/}), while for \textipa{/hp/}-clusters, it was a copy of the flanking vowel. Finally, and most importantly, in items where the coarticulation and flanking vowel differed, the quality of the epenthetic vowel was significantly influenced by both variables, but the influence of the former was much larger than that of the latter, especially in the case of /hp/. Our discussion focuses on this last finding. 

Before discussing its theoretical relevance, let us comment on the numerically small -- yet significant -- influence of flanking vowel on epenthesis for \textipa{/hp/}-clusters, where vowel coarticulation is maximal. This result suggests a contribution of categorical variables on epenthetic vowel quality (i.e., copy effect). A similar effect, though, was also found for \textipa{/kp/}-clusters, for which loanword adaptation patterns provide no particular reason to propose the existence of a categorical copy phenomenon; indeed, in loanwords, coda-/k/ generally triggers default /u/-epenthesis. 
Therefore, it is possible that this effect results from a response bias due to task demands: given a perceptually uncertain stimulus, the flanking vowel could prime a `copy' response, for instance, because it was visually available on-screen at each trial (e.g. ``ah?pa"). Further work using different tasks is necessary to examine the perceptual reality of this `vowel copy' effect.

\begin{figure}[h!]
  \centering
  \begin{overpic}[page=1, width=0.7\linewidth]{chapter02/ahpa_acoustic}\end{overpic}
  \caption{{\color{blue}\textit{Visualisation in $F1 \times F2$ space of full vowels extracted from $CVC$ portions (left panels), and coarticulation found in the first consonant of $C_{V}C$ clusters (right panels), of items used in the experiment. Dimmer dots and lines respectively show median formant values and median formant bandwidths within the vowel or consonant. Dots circled in black and thicker lines show global means.}}}
  \label{fig:ahpa_acoustic}
\end{figure}

Keeping in mind that this work focuses on the choice of epenthetic vowel, while not directly addressing questions related to why phonologically-illegal clusters are repaired, or what the role of phonotactics in epenthesis is, the finding that the quality of the epenthetic vowel is influenced more by coarticulation than by the flanking vowel calls for a perceptual repair mechanism in which acoustic details are taken into consideration. Two-step models in which epenthetic repair is performed after the consonant cluster in the acoustic input has been represented in terms of discrete phonetic categories are therefore ruled out. Rather, like \cite{dupoux2011}, we argue in favor of one-step models, in which epenthetic vowel quality is based on the similarity between local acoustic cues and prototypical properties of each vowel in the language, such that the closest matching vowel gets selected for insertion. This mechanism can account both for the coarticulation-induced vowel copy effect in items with a \textipa{/hp/}-cluster, as the voiceless glottal fricative /h/ contains strong coarticulation from the adjacent vowels {\color{blue}\cite{keating1988} also see Figure \ref{fig:ahpa_acoustic}}, %https://osf.io/y9h6c for supplementary data]{keating1988},
and for the default /u/-epenthesis effect in items with a \textipa{/kp/}-cluster -- which exhibit a lower degree of coarticulation -- as \textipa{/u/} is the phonetically shortest vowel in the language \cite{han1962} and is prone to be devoiced in certain contexts (see footnote).

Focusing on cases where the quality of the epenthetic vowel varies \textit{within language} as a function of the type of cluster, previous studies have investigated whether language-specific phonotactic or phonological properties play a role for the quality of the epenthetic vowel. In Japanese, for instance, dental stops cannot be followed by /u/, and in loanwords this phonotactic constraint gives rise to adaptation by means of /o/-epenthesis (e.g. $'batman' \rightarrow 'batoman'$). Using identification tasks, both \cite{mattingley2015} and \cite{guekozIS17} report that the perceptual equivalent of this effect is only marginally present in Japanese listeners \cite[10-12\% of /o/-epenthesis in /d/-initial clusters; see also][for the absence of such an effect in a discrimination task]{monahan2009}. Thus, so far there is only weak evidence that the mechanism of phonotactic repair takes into account the legality of the resulting CVC-sequence. A stronger effect of cluster-dependent perceptual epenthesis has been reported in Korean listeners, who repair \textipa{/eSma/} and -- to a lesser extent -- \textipa{/ec\super hma/} with an epenthetic \textipa{/i/} instead of the default epenthetic vowel \textipa{/1/} \cite{durvasula2015}. This is argued to be due to the existence of an allophonic rule that palatalizes \textipa{/s/} and \textipa{/t\super h/} before \textipa{/i/}, yielding \textipa{[Si]} and \textipa{[c\super hi]}, respectively. It is also possible, however, that this effect is (partly) due to coarticulation; for instance, acoustic cues in \textipa{/S/} and \textipa{/c\super h/} might be more suggestive of \textipa{/i/} than of \textipa{/1/}.  

To conclude, we directly compared the relative contributions of acoustic and categorical effects on epenthetic vowel quality, and found that the former override the latter. This result thus strengthens those of \cite{dupoux2011}, who also established the presence of acoustic effects but without investigating possible categorical effects. More research is needed to investigate whether our findings generalize to other cases of perceptual epenthesis. This question can be addressed by two complementary approaches. One would be to run additional experiments with cross-spliced stimuli, as in the present study. Another one would be to measure the effective amount of coarticulation in experimental stimuli of previous studies, using a computational implementation of a one-step repair mechanism (see \cite{dupoux2011} and \cite{wilson2014} for propositions, and \cite{schatz2016} for an implementation using Hidden Markov Models).

%%%% Annexes %%%%
\subsection{Annexes}
\begin{figure}[ht!]
  \centering
  \begin{overpic}[page=4, width=0.9\linewidth]{chapter02/ahpa_tiles}\end{overpic}
  \begin{overpic}[page=3, width=0.9\linewidth]{chapter02/ahpa_tiles}\end{overpic}
  \begin{overpic}[page=2, width=0.9\linewidth]{chapter02/ahpa_tiles}\end{overpic}
  \caption{{\color{blue}\textit{Counts of responses for the test items and spliced control items, separated by speaker. For each speaker: top: \textipa{/hp/-}items; bottom: \textipa{/kp/-}items. Within each individual rectangle, flanking vowels and vowel coarticulation are given in the horizontal and vertical axes, respectively. Darker colours indicate higher counts, with colours normalized within each speaker.}}}
  \label{fig:ahpa_spk}
\end{figure}

\subsection{Supplementary experiment: ABX task}

{\color{blue}In this additional experiment we assessed the perception of illegal consonantal clusters in Japanese using an ABX discrimination task, which, contrary to the vowel identification task used in Experiment 1, does not require an explicit categorization of the item's segments. As in previous work \cite{dupoux1999, dupoux2011}, we used different speakers for stimuli A, B, and X, such that the task could not be performed on the basis of low-level acoustic information.

\subsubsection{Methods}
\paragraph{Participants}
Twenty-six native Japanese listeners were recruited in Paris, France %(mean age $XX \pm X.X$; XX female).
While testing for this experiment was done outside of Japan, we recruited only participants with little experience with French or other languages in which consonant clusters are allowed. For instance, many participants were recently arrived exchange students or family members of professionals that had been transferred to Paris.  

\paragraph{Stimuli}
From the stimuli used for the identification task, we extracted items relevant for pairs shown in Table \ref{ahpa_ab_pairs}.
We defined four types of AB pairs with constant flanking vowels, based on the nature of the items in the pair:

\begin{itemize}
\item Natural cluster items (N) correspond to natural control stimuli from the identification task, disyllabic $V_{1}C_{1}C_{2}V_{1}$ items which have not been spliced.
\item Spliced cluster items (Sp) correspond to the identification task test stimuli, disyllabic $V_{1}C_{1}(V_{2})C_{2}V_{1}$ items for which the $C_{1}(V_{2})C_{2}$ cluster has been spliced from a $V_{2}C_{1}C_{2}V_{2}$ item.
  \item Full vowel items (FV) correspond to trisyllabic fillers from the identification task, $V_{1}C_{1}V_{2}C_{2}V_{1}$ items for which the $C_{1}V_{2}C_{2}$ cluster has been spliced from a $V_{2}C_{1}V_{2}C_{2}V_{2}$ item
\end{itemize}

\begin{table*}[h]
\centering
\caption{Types of AB pairs for Experiment 2.} 
\label{ahpa_ab_pairs}
\begin{tabular}{ccccc}%cccc}
\toprule
%&&&&& \multicolumn{4}{c}{Predicted accuracy} \\
\multicolumn{1}{c}{Type} & A & B & \# pairs & Example \\ %& Overt$_{(1)}$ & Covert$_{(2)}$ & \textipa{/u/}$_{(3)}$ & None$_{(3)}$\\ 
\midrule
N-FV  & natural & full vowel & 10  & \textipa{$/ahpa/ - /ahapa/$} \\ %& $-$ & $-$ & $+$ & $+$ \\
N-Sp  & natural & spliced    & 40  & \textipa{$/ahpa/ - /ah_{i}pa/$} \\ %& $-$ & $+$ & $-$ & $-$       \\
Sp-Sp & spliced & spliced    & 100 & \textipa{$/ah_{i}pa/ - /ah_{e}pa/$} \\%& $-$ & $+$ & $-$ & $-$  \\
Sp-FV & spliced & full vowel & 50  & \textipa{$/ah_{i}pa/ - /ahipa/$} \\%& $+$ & $-$ & $+$ & $+$ \\
\bottomrule
\end{tabular}
\end{table*}

\paragraph{Procedure}
Participants were tested in a soundproof room with headphones. On each trial, participants heard two different stimuli of categories A and B, followed by a third stimulus X, belonging either to category A or B. All three stimuli had a $\textipa{V_{1}C(V_{2})pV_{1}}$ structure, with \textipa{$V_{1}$} and \textipa{$C$} remaining constant within each trial.  
All three tokens heard at each trial were produced by different speakers. Stimuli within each trial were presented with an ISI of 500 ms, and an ITI of 1 s separating a participant's response from the following trial.  

Within each triplet, A always contained either a natural or a spliced cluster, while B always contained either a full vowel or a spliced cluster. Table \ref{table:ahpa_ab_pairs} shows the four different types of AB pairs that were thus tested. 

In total, there were 200 AB pairs. Since there are four possible presentation orders for each pair and its corresponding third item X (i.e., $ABX_A$, $BAX_A$, $ABX_B$, $BAX_B$), there are 800 possible unique trials. In order to reduce the duration of the experiments, participants were divided into two groups exposed to counterbalanced halfs of the total set of trials.    

\subsubsection{Results}

\begin{figure}[H] 
\centering
    \begin{overpic}[page=5, width=\linewidth]{chapter02/ahpa_figs.pdf}
    \end{overpic}
    
    \caption{{\color{blue}\textit{Discrimination accuracy at the ABX task on /hp/ (left) and /kp/ (right) items. Dot plots show the distribution of average scores (one dot per participant). Horizontal grey lines show mean accuracy for each AB pair type.}}}
    \label{fig:ahpa_ABX}
  \end{figure}
  
Trials in which the response was given before all items in the ABX triplet had been played were excluded ({\color{red}XX trials representing XX\%}). %[TODO]
The remaining data were analysed using a generalised linear mixed-effects model in R (\textit{lme4}; \cite{R-lme4}) with a declared binary distribution. The binomial response variable of interest for each trial was Accuracy (\textit{correct vs. incorrect}); were included as fixed effects Consonant (\textit{\textipa{/h/} vs. \textipa{/k/}}), $Type_{A}$ (\textit{natural vs. spliced}), $Type_{B}$ (\textit{full vowel vs. spliced}), as well as the interactions between every pair of fixed effects. All fixed effects were contrast-coded. Participant, $Item_A$, $Item_B$, and Test Group were included as random effects. Significance testing was done through model comparison: the full model including all fixed and random effects was compared to reduced models, in which one of the fixed effects was absent.

The full model did not explain significantly more data variance than a model excluding the fixed effect Consonant, suggesting that participant accuracy was not significantly different for \textipa{/hp/} and \textipa{/kp/} trials ($\beta = 0.17$, $SE = 0.16$, $\chi^2(1) = 1.1$, $p > 0.05 $).

We did not find evidence of accuracy being lower or higher when an ABX trial contained a natural cluster item instead of a spliced cluster item ($Type_A$; $\beta = 0.20$, $SE = 0.12$, $\chi^2(1) = 2.52$, $p > 0.05$). Moreover, there was no significant interaction between Consonant and $Type_A$ ($\beta = -0.10$, $SE = 0.17$, $\chi^2(1) = 0.37$, $p > 0.05$), nor between $Type_A$ and $Type_B$ ($\beta = 0.08$, $SE = 0.15$, $\chi^2(1) = 0.26$, $p > 0.05$).

By contrast, accuracy was significantly enhanced by the presence of an item with a full vowel cluster (i.e., \textit{Sp-FV} and \textit{N-FV} pairs) ($Type_B$, $\beta = 0.93$, $SE = 0.16$, $\chi^2(1) = 29.8$, $p < 0.0001$). This increase in accuracy appears to be exacerbated in pairs with \textipa{/kp/}-containing items relative to pairs with \textipa{/hp/}-containing items, as the interaction between Consonant and $Type_B$ was also significant ($\beta = -0.7$, $SE = 0.15$, $\chi^2(1) = 19.0$, $p < 0.0001$).

\subsubsection{Correlation between experimental results}

In order to assess the role of perceptual assimilation on stimulus discrimination, we derived a measure of perceptual distance from response patterns given in the identification task, and examined if this distance predicted the outcome in the ABX discrimination task. To do so, we computed for each item a six-dimensional numerical vector of the shape $x = [x_{1}, ..., x_{6}]$, with values corresponding to the percent responses to categories \textipa{a}, \textipa{e}, \textipa{i}, \textipa{o}, \textipa{u}, and \textit{none}, respectively. The distance $d(x,y)$ between two items $x$ and $y$ was computed as the normalized Euclidian distance between their associated vectors:
    \[d(x,y)=\frac{\sqrt{\sum_i (x_{i} - y_{i})^{2}}} {\sqrt{2}}\]

One data point was obtained per AB pair, giving a total of 200 datapoints (cf. Table \ref{ahpa_ab_pairs}).

%% Statistical analysis: Multiple regression
\begin{figure}[H]
\centering
    \begin{overpic}[page=6, height=8cm]{chapter02/ahpa_figs.pdf}
    \end{overpic}
    
    \caption{{\color{blue}\textit{Correlation between the perceptual distance derived from the identification task responses and the accuracy at the ABX discrimination task.}}} 
    \label{fig:ahpa_corr}
\end{figure}

Multiple regression analysis was used to test if assimilation patterns from the identification task significantly predicted participants' accuracy during the ABX task. A scatterplot summarizes the results in Figure \ref{fig:ahpa_corr}. The model included as independent variables the normalized perceptual distance between two items (range = [0;1]), and the consonant cluster (\textipa{/hp/} or \textipa{/kp/}). These two predictor variables explained 52\% of the variance ($R^{2} = 0.52$, $F(3,196) = 73.63$, $p < 0.0001$). Consonant cluster ($t < 1$) and the interaction of the two independent variables ($t < 1$) were not statistically significant. On the other hand, perceptual distance significantly predicted accuracy during the ABX task ($t = 13.8$, $p < 0.0001$); the less similar the response patterns to both items in the AB pair, the easier their discrimination in the ABX task. These results suggest that adaptation patterns attested in the identification task are not task-dependent.}


%%%%%%%%%%%%%%%%%%%%%%%%%%
% Parlato1 (Interspeech) %
%%%%%%%%%%%%%%%%%%%%%%%%%%

% %%%% Main %%%%
% \includepdf[pages={1-5},pagecommand={},
% addtotoc={
%   1,section,1,Predicting epenthetic vowel quality from acoustics,parlato1_main,
%   1,subsection,2,Perception experiment,parlato1_per,
%   2,subsection,2,Acoustic analyses,parlato1_prod,
%   3,subsection,2,Production-based exemplar model,parlato1_mod,
%   4,subsection,2,Discussion,parlato1_disc,
%   5,subsection,2,References,parlato1_ref
% }]
% {images/chapter02/Interspeech2017_Predicting_epenthetic_vowel_quality_from_acoustics_final.pdf}

\newpage
\section{Predicting epenthetic vowel quality from acoustics} \label{2-parlato}

%[TODO] Say that this is a modified version of the Interspeech paper

\textit{{\color{blue}The following section is a modified version of the following conference proceedings: \\
Guevara-Rukoz, A., Parlato-Oliveira, E., Yu, S., Hirose, Y., Peperkamp, S., and Dupoux, E. (2017). Predicting epenthetic vowel quality from acoustics. Proceedings of Interspeech, 596-600.}}

\paragraph{Abstract}
Past research has shown that sound sequences not permitted in our native language may be distorted by our perceptual system. A well-documented example is vowel epenthesis, a phenomenon by which listeners hallucinate non-existent vowels within illegal consonantal sequences. As reported in previous work, this occurs for instance in Japanese (JP) and Brazilian Portuguese (BP), languages for which the `default' epenthetic vowels are /u/ and /i/, respectively. In a perceptual experiment, we corroborate the finding that the quality of this illusory vowel is language-dependent, but also that this default choice can be overridden by coarticulatory information present on the consonant cluster. In a second step, we analyse recordings of JP and BP speakers producing `epenthesized' versions of stimuli from the perceptual task. Results reveal that the default vowel corresponds to the vowel with the most reduced acoustic characteristics and whose formants are acoustically closest to formant transitions present in consonantal clusters. Lastly, we model behavioural responses from the perceptual experiment with an exemplar model using dynamic time warping (DTW)-based similarity measures on MFCCs. 

\subsection{Introduction}

When languages borrow words from one another, the borrowed words tend to be adapted to the local phonology. For instance, Brazilian Portuguese phonotactic constraints disallow most obstruent-obstruent and obstruent-nasal sequences, while those of Japanese disallow consonant clusters and consonants in coda position (with the exception of geminates and nasal consonants). Foreign words containing these illegal sequences may be broken up by the insertion of so-called `epenthetic' vowels (e.g., BP: "football" $\rightarrow$ \textipa{/futibol/}, JP: "ice cream" $\rightarrow$ \textipa{/aisukuri:mu/}). This phenomenon has been shown to also happen during on-line perception: listeners \textit{perceive} vowels within illegal consonantal sequences \cite{dupoux1999, dehaene2000, dupoux2001, berent2007, kabak2007, monahan2009, dupoux2011, mattingley2015, durvasula2015}. This suggests that phonotactic constraints of the native language play an active role during speech perception and induce repair of illegal forms such that they are recoded into the nearest legal one. The specific mechanisms of this repair process are still largely unknown. In particular, what determines the quality of the epenthesized vowel? Past work has shown that perceptual epenthesis is language-dependent (e.g., /i/ in BP, /u/ in JP), but also that it may be influenced by local acoustic properties, i.e., by coarticulation \cite{dupoux2011}. Here, we study these two effects together, and report, firstly, on a perception experiment with BP and JP listeners. Next, we conduct acoustic analyses of the production of possible epenthetic vowels in a subset of the same participants.
Lastly, we present an exemplar-based computational model of speech perception which attempts to model phonotactic repairs based on acoustics.

\subsection{Perception experiment} \label{2-parlato_per}

We assess patterns of perceptual epenthesis by BP and JP native listeners on stimuli containing an illegal cluster. We investigate (1) the preferred epenthetic vowel in the two languages (/i/ vs. /u/), and (2) the influence of flanking vowels on responses.    

\subsubsection{Methods}

Fifty-four items with the structure $V_{1}C_{1}C_{2}V_{2}$, with $V_{1}$ and $V_{2}$ vowels from the set \{/a/, /i/, /u/\}, and $C_{1}C_{2}$ a cluster from the set \{/bg/, /bn/, /db/, /dg/, /gb/, /gn/\}, e.g. /abgi/, were recorded by a native speaker of French. Twenty-two native BP listeners and 17 native JP listeners were tested in S\~{a}o Paulo and Tokyo, respectively. None had extensive exposure to languages that allow complex consonantal clusters. At each trial, participants heard a stimulus and had to indicate within 3 seconds which vowel from the set \{/a/, /e/, /i/, /o/, /u/ and \textit{none}\} they perceived within the consonant cluster. 

\subsubsection{Results}
Statistical analyses were performed with the R statistical software \cite{R-base}, using MCMC glmm \cite{R-MCMCglmm, R-coda}. Effects were considered statistically significant if the 95\% highest posterior density (HPD) interval estimated for the variable of interest did not include zero. Please note that we only report effects relevant to hypotheses tested in this work. A full report of all analyses conducted in this section (as well as additional information) can be found in: https://osf.io/zr88w/.

In order to assess the influence of $V_{1}$ and $V_{2}$ (henceforth: flanking vowels) on epenthetic vowel quality (/i/ or /u/), we fitted models with fixed effects Language (BP \textit{vs.} JP), Number of Same Flanking Vowels (NSFV) ($none$ \textit{vs.} $1$; $none$ and $1$ \textit{vs.} $2$) and their interaction, with Participants as random effect. We also included the fixed effect Coronal $C_{1}$ (non-coronal \textit{vs.} coronal) and the resulting interactions when analysing /u/ responses, as the insertion of default /u/ after coronal consonants yields phonotactically illegal sequences in Japanese. Fixed effects were contrast coded with deviance coding and, in the case of the trinomial variable NSFVs, comparisons were achieved by creating dummy variables "none \textit{vs} 1" with weights [-0.5, 0.5, 0] for levels $none$, $1$ and $2$, respectively, and "Less than 2 \textit{vs.} 2" with weights [-0.25, -0.25, 0.5] for levels $none$, $1$ and $2$.

\begin{figure}[H]
  \centering
  \begin{overpic}[page=1, width=0.6\linewidth]{chapter02/parlato_tiles}\end{overpic}
  \begin{overpic}[page=2, width=0.6\linewidth]{chapter02/parlato_tiles}\end{overpic}
  \caption{\textit{{\color{blue}Responses for all trials from the perception experiment for both BP (top) and JP (bottom), including trials with responses not given by the exemplar model (``none'', ``a'', ``e''). Numbers indicate trial counts, with darker cell backgrounds representing higher values. Within each of the two 3 x 3 grid, trials are separated according to $V_{1}$ (columns) and $V_{2}$ (rows). % [TODO] Check that this is the case and not the other way around 
    Within each individual rectangle, the horizontal axis shows the first consonant of the consonant cluster, while the vertical axis corresponds to possible responses.}}}
  \label{fig:parlato_per_all}
\end{figure}

{\color{blue}Response patterns are shown on Figure \ref{fig:parlato_per_all}.} Overall, BP and JP participants experienced vowel epenthesis in 81\% and 87\% of the trials, respectively. We focus our analysis on these trials and, in order to allow for comparisons with the model from Section 4 below, we exclude trials for which the reported epenthetic vowel was /a/ (1\%) or /e/ (BP: 1\%, JP: 3\%). Percentages for the remaining responses of interest (/i/, /o/, and /u/) can be seen in the lefthand part of Table~\ref{tab:parlato_model_overall}. 

% latex table generated in R 3.2.3 by xtable 1.8-2 package
% Sun Mar 19 23:36:24 2017
\begin{table}[th]
  \caption{Percentage of responses.}
  \label{tab:parlato_model_overall}
\centering
    \begin{tabular}{ccccccc}
    \toprule
        & \multicolumn{3}{c}{Human data} & \multicolumn{3}{c}{Model} \\
        \cmidrule(lr){2-4}\cmidrule(lr){5-7} 
        & i & o & u & i & o & u \\ 
    \midrule
        BP & $80.39$ & $0.64$ & $18.97$ & $52.73$ & $6.22$ & $41.05$ \\ 
        JP & $18.37$ & $5.64$ & $75.98$ & $49.34$ & $0.13$ & $50.52$ \\ 
    \bottomrule
    \end{tabular}
\end{table}

\paragraph{/i/-epenthesis}

\begin{figure}[h!]
  \centering
  \begin{overpic}[page=1, width=0.45\linewidth]{chapter02/parlato_per_iou}\end{overpic}
  \hspace{1cm}
  \begin{overpic}[page=3, width=0.45\linewidth]{chapter02/parlato_per_iou}\end{overpic}
  \caption{\textit{{\color{blue}Proportion of /i/-epenthesis in the perception experiment with BP and JP participants (left) and the simulations with the corresponding exemplar-based models (right). Bigger dots show mean values, while smaller dots show individual values for human participants.}}}
  \label{fig:parlato_iepenth}
\end{figure}

{\color{blue}Figure \ref{fig:parlato_iepenth} shows the proportion of /i/-epenthesis.} A main effect of Language shows that BP participants perceived an epenthetic /i/ more often than JP participants (posterior mode: $-277.1$, HPD interval: $[-389.2, -167.1]$). Moreover, the propensity to respond /i/ was influenced by flanking vowels, as indicated by a main effect of NSFV: Participants gave more /i/ responses when one flanking vowel was /i/ ($204.1, [80.8, 283.7]$), and even more so when both flanking vowels were /i/ ($368.9, [208.4, 443.4]$). 

\paragraph{/u/-epenthesis}

\begin{figure}[h!]
  \centering
  \begin{overpic}[page=2, width=0.45\linewidth]{chapter02/parlato_per_iou}\end{overpic}
  \hspace{1cm}
  \begin{overpic}[page=4, width=0.45\linewidth]{chapter02/parlato_per_iou}\end{overpic}
  \caption{\textit{{\color{blue}Proportion of /u/-epenthesis in the perception experiment with BP and JP participants (left) and the simulations with the corresponding exemplar-based models (right). Bigger dots show mean values, while smaller dots show individual values for human participants.}}}
  \label{fig:parlato_uepenth}
\end{figure}

{\color{blue}Figure \ref{fig:parlato_uepenth} shows the proportion of /u/-epenthesis.} We found a main effect of Language; BP participants epenthesized /u/ less often than JP participants ($265.2, [191.0, 347.2]$). The significant main effect of NSFV shows that participants were overall more prone to perceiving an epenthetic /u/ if one ($137.0, [90.6, 185.4]$) or both ($300.3, [230.4, 387.7]$) flanking vowels were /u/. Lastly, there was also a main effect of Coronal $C_{1}$ ($-43.0, [-75.8, -9.8]$): participants perceived /u/ less often after coronal than after labial and velar consonants. However, neither the interaction between Coronal $C_{1}$ and Language ($-63.9, [-132.1, 3.0]$), nor the triple interactions with NSFV ($-17.8, [-124.9, 84.1]$, $-14.8, [-238.4, 304.3$) were significant; thus, JP participants were not more prone to avoiding /u/-epenthesis after coronal consonants than BP participants. 


\subsection{Acoustic analyses}

In both BP and JP, the shortest vowel corresponds to the default epenthetic vowel, i.e. /i/ in BP \cite{escudero2009} and /u/ in JP \cite{han1962}. Here, we compare epenthetic vowels /i/, /u/, and /o/ on three acoustic parameters: (1) vowel duration, (2) vowel intensity, and (3) Euclidean distance between vowel formants and formant transitions in consonant clusters. We hypothesize that, for both languages, the default vowel is the one (1) that is shortest, (2) that has the lowest intensity, and (3) whose formants are closest to the formant transitions present in consonantal clusters.       

\subsubsection{Methods}

Seventeen BP and 17 JP participants from the perception experiment were also recorded producing 162 stimuli obtained by crossing the 54 $V_{1}C_{1}\_C_{2}V_{2}$ frames of the experimental items with the three vowels /i/, /o/, and /u/ (e.g. $/ab\_gi/ \rightarrow /abigi/, /abogi/, /abugi/$).
Items were read aloud in carrier sentences, with stress and pitch accent on the first syllable for BP and JP speakers, respectively. The recordings were manually segmented and transcribed by a trained phonetician. Recordings with errors or unwanted noise were excluded from the analyses. Acoustic measurements were automatically extracted from the speech signal using the R package wrassp \cite{R-wrassp}.

\subsubsection{Results}

For each of the continuous response variables examined in this section, we fitted an MCMC glmm with fixed effects Language (BP \textit{vs.} JP), Medial Vowel (/i/ \textit{vs.} /u/; /i/ and /u/ \textit{vs.} /o/) and their interaction, with Participant and Item as random effects. Fixed effects were contrast coded with deviance coding and, in the case of the trinomial variable Medial Vowel, the comparisons were achieved by creating a dummy variable "/i/ \textit{vs} /u/" with weights [-0.5, 0, 0.5] for levels /i/, /o/ and /u/, respectively, and one for "High Vowels \textit{vs.} /o/" with weights [-0.25, 0.5, -0.25]. Multiple pairwise comparisons, using Least Squares Means (LSMEANS) and Tukey's adjustment, were performed using the R package lsmeans \cite{R-lsmeans}.

\paragraph{Vowel duration}

\begin{figure}[h!]
  \centering
  \begin{overpic}[clip, trim=0 0 0 0, page=1, width=0.9\linewidth]{chapter02/parlato_acoustic}\end{overpic}
  \caption{\textit{{\color{blue}Distribution of log'd vowel duration (in s) of medial vowels /i, o, u/ produced by BP and JP participants. Dashed lines show mean values.}}}
  \label{fig:parlato_prod_dur}
\end{figure}

The measured duration of each medial vowel $V_{3}$ (in seconds) was log-transformed to account for distribution skewness. {\color{blue}The resulting distributions can be seen in Figure \ref{fig:parlato_prod_dur}.} We found a main effect of Medial Vowel ("/i/ \textit{vs} /u/": $0.04$, $[0.02, 0.06]$; "High Vowels \textit{vs.} /o/": $0.32$, $[0.30, 0.34]$), showing that, overall, /o/ is longer than /u/, which is longer than /i/. The interaction of Language and Medial Vowel was also significant ("/i/ \textit{vs} /u/": $-0.15$, $[-0.18, -0.10]$), reflecting the fact that in BP, /i/ is shorter than /u/ (mean /i/: $57.2$ ms; mean /u/: $64.5$ ms; adjusted $p<0.05$) while in JP, /u/ is shorter than /i/ (mean /u/: $69.6$ ms; mean /i/: $72.0$ ms; adjusted $p<0.05$).

\paragraph{Vowel intensity}

\begin{figure}[h!]
  \centering
  \begin{overpic}[clip, trim=0 0 0 0, page=2, width=0.9\linewidth]{chapter02/parlato_acoustic}\end{overpic}
  \caption{\textit{{\color{blue}Distribution of median intensity (in dB) of medial vowels /i, o, u/ produced by BP and JP participants. Dashed lines show mean values.}}}
  \label{fig:parlato_prod_dB}
\end{figure}

We compared the mean intensity of the medial vowels $V_{3}$ in decibels (dB). {\color{blue}The associated distributions can be seen in Figure \ref{fig:parlato_prod_dB}.} There was a main effect of Medial Vowel, with /i/ having on average lower intensity than /u/ ($0.8$, $[0.7, 1.1]$), and high vowels having lower intensity than /o/ ($2.1$, $[1.9, 2.4]$). Of interest is the fact that the former effect is larger for JP than for BP (Language x "/i/ \textit{vs} /u/": $0.38$, $[0.09, 0.90]$), meaning that while /i/ is the vowel with least intensity in BP (mean: $72.8$ dB \textit{vs.} $73.2$ for /u/; adjusted $p<0.05$), the reverse is not true for JP (mean: $69.7$ dB for /u/ \textit{vs.} $68.7$ for /i/, adjusted $p<0.05$).
This might be due to an overall higher degree of vocal constriction during the production of /i/ compared to /u/.  

\paragraph{Vowel formants}

\begin{figure}[h!]
  \centering
  \begin{overpic}[clip, trim=0 0 0 0, page=3, width=0.9\linewidth]{chapter02/parlato_acoustic}\end{overpic}
  \caption{\textit{{\color{blue}Distribution of square root Euclidean distance to template in F1 x F2 x F3 space (frequencies in Bark) of medial vowels /i, o, u/ produced by BP and JP participants. Dashed lines show mean values.}}}
  \label{fig:parlato_prod_eucl}
\end{figure}

We extracted median formant values (F1, F2, and F3, in Bark) from medial vowels $V_{3}$ and computed their Euclidean distance to the transitions found within their respective clusters (e.g. the /i/ in /abiga/ was compared to transitions in /bg/ from the French recording of /abga/). {\color{blue}The resulting distributions can be seen in Figure \ref{fig:parlato_prod_eucl}.} These Euclidean distances were square-root transformed to account for skewness. There was a main effect of Medial Vowel, as on average distance was shorter for /u/ than for /i/ ($-0.06$, $[-0.08, -0.04]$), while it was longer for /o/ relative to both /i/ and /u/ ($0.28$, $[0.25, 0.30]$). Of interest is the significant interaction between Language and Medial Vowel "/i/ \textit{vs} /u/" ($-0.31$, $[-0.36, -0.28]$), reflecting the fact that in BP /i/ formants were closer to cluster transitions than /u/ formants (mean: /i/ $2.8$ \textit{vs.} /u/ $3.1$, adjusted $p<0.05$), while the reverse held in JP (mean: /i/ $2.9$ \textit{vs.} /u/ $2.2$, adjusted $p<0.05$). 

\subsection{Production-based exemplar model}

We built an exemplar model of the perception of phonotactically illegal consonant clusters by BP and JP listeners, exclusively based on acoustics. We used all participants' productions from Section 3 as the inventory of exemplars available to our model. This is a simple way of representing the acoustics that a BP/JP native listener may have been exposed to during language development. As an analogy to the perception experiment from Section 2, the model classified each $V_{1}C_{1}C_{2}V_{2}$ template as $V_{1}C_{1}iC_{2}V_{2}$, $V_{1}C_{1}oC_{2}V_{2}$, or $V_{1}C_{1}uC_{2}V_{2}$, based on the similarity of the template to exemplars of these three categories available in the inventory. We examined whether the model was able to predict participants' epenthetic patterns, in particular, whether it was able to mimic preferences for default vowels and capture the modulation of these preferences induced by flanking vowels.   

\subsubsection{Methods}
Recordings from Section 3 were converted into sequences of 39-dimensional feature vectors consisting of 12 Mel-frequency cepstral coefficients (MFCCs) and energy features\footnote{Due to a mistake in the feature computation pipeline, this meant that the log energy and the 12 first MFC coefficients were concatenated, not that the first coefficient of 13 coefficients was replaced by the log energy, as was originally intended.}, with delta and delta-delta coefficients. Coefficient values were standardised. We computed the optimal alignment between all $V_{1}C_{1}C_{2}V_{2}$ templates (e.g. /abgi/) and their corresponding $V_{1}C_{1}V_{3}C_{2}V_{2}$ epenthesized versions (e.g. /abigi/, /abogi/, /abugi/) using Dynamic Time Warping (DTW) \cite{sakoe1978, R-dtw}. In order to ensure that the resulting distances were not mainly influenced by spectral differences of flanking vowels $V_{1}$ and $V_{3}$, we only compared $C_{1}C_{2}$ clusters to $C_{1}V_{3}C_{2}$ sections. Note, however, that coarticulation cues from flanking vowels are expected to be present within the clusters. 

For the simulation, we built a classifier that assigns any given template to one category in the set \{$V_{1}C_{1}iC_{2}V_{2}$, $V_{1}C_{1}oC_{2}V_{2}$, $V_{1}C_{1}uC_{2}V_{2}$\}, based on acoustic similarity. Similarity $s$ between templates and epenthesized versions was defined as
% 
\begin{equation}
  s = e^{-cd}
  \label{eq1}
\end{equation}
% 
where $d$ is the DTW distance, and $c$ is a parameter determining the weight of the DTW distance on classification \cite{nosofsky1992}. When $c = 0$, DTW is disregarded and all possible classification categories are equally probable. Higher values of $c$ result in higher probabilities being given to items with smaller $d$. In order to control for unequal number of tokens in each category, classification was performed by computing the mean similarity within each category. From there we sampled a classification label weighting category probabilities by the resulting mean similarity weights. Parameter $c$ was individually optimised for each language by performing leave-one-out cross-validation (maximum accuracy: $0.50$ with $c = 0.5$ for BP, and $0.63$ with $c = 2.2$ for JP; chance level at $0.33$). 

\subsubsection{Results}

The same statistical models from Section 2, but without a random effect for Participant, were used.

The perception model was able to accurately predict participant responses for 59.1\% (BP) and 58.4\% (JP) of trials. Figure~\ref{fig:parlato_permod} shows a detailed distribution of the responses. As shown in the righthand part of Table~\ref{tab:parlato_model_overall}, the model rarely predicted /o/ responses, as expected based on acoustic analyses; however, it is surprising that most /o/ responses were predicted for BP rather than for JP. This might be due to overlap of /u/ and /o/ in the formant space of BP, which is visible in Figure~\ref{fig:parlato_prod_formants}.

\begin{figure}[th!]
  \centering
  \begin{overpic}[clip, trim={0 0 0 0}, width=\linewidth]{chapter02/parlato_fig2.pdf}  
  \end{overpic}
  \caption{\textit{Medial vowels and clusters in F1 x F2 space.}}
  \label{fig:parlato_prod_formants}
\end{figure}

Concerning /i/ and /u/, numerically the model predicted more /i/ responses than /u/ responses for BP, and the opposite for JP. However, these differences are not as clear as they are for our human data, where in both languages the default vowel is chosen four times more often than the non-default high vowel.

\begin{figure*}[th]
  \centering
    \begin{overpic}[clip, trim={0 0 0 0}, page=3, width=0.35\linewidth]{chapter02/parlato_tiles.pdf}  
    \end{overpic}%
    \hspace{1.5cm}
    \begin{overpic}[clip, trim={0 0 0 0}, page=5, width=0.35\linewidth]{chapter02/parlato_tiles.pdf}  
    \end{overpic} 
    
    \vspace{0.2cm}
    \centering
    
    \begin{overpic}[clip, trim={0 0 0 0}, page=4, width=0.35\linewidth]{chapter02/parlato_tiles.pdf}  
    \end{overpic}%
    \hspace{1.5cm}
    \begin{overpic}[clip, trim={0 0 0 0}, page=6, width=0.35\linewidth]{chapter02/parlato_tiles.pdf}  
    \end{overpic}
  \caption{\textit{Responses from the perception experiment (left) and model predictions (right), for both BP (top) and JP (bottom), on trials common to the human and model experiments. Numbers indicate trial counts, with darker cell backgrounds representing higher values. Within each 3 x 3 grid, trials are separated according to $V_{1}$ (columns) and $V_{2}$ (rows). Within each individual rectangle, the horizontal axis relates to whether $C_{1}$ is coronal (/d/) or not, while the vertical axis corresponds to possible responses. For instance, BP participants experienced /i/-epenthesis in all 78 trials involving $/iC_{1}C_{2}a/$ stimuli for which $C_{1}$ was not the coronal consonant /d/.}}
  \label{fig:parlato_permod}
\end{figure*}

\paragraph{/i/-epenthesis}

{\color{blue}Figure \ref{fig:parlato_iepenth} shows the proportion of /i/-epenthesis for human participants and the corresponding exemplar models.}
We found a main effect of Language ($-52.0$, $[-86.9, -23.8$) and a main effect of NSFV ($none$ \textit{vs.} $1$: $93.3$, $[53.0, 125.0]$; Less than $2$ \textit{vs.} $2$: $245.7$, $[150.8, 328.2]$). 
Thus, our model is able to reflect the higher frequency of /i/ as epenthetic vowel in BP compared to JP participants, as well as the influence of flanking vowels on /i/-epenthesis in both BP and JP. 

\paragraph{/u/-epenthesis}

{\color{blue}Figure \ref{fig:parlato_uepenth} shows the proportion of /u/-epenthesis for human participants and the corresponding exemplar models.}
We found a main effect of NSFV ($none$ \textit{vs.} $1$: $37.8$, $[16.0, 62.3]$; Less than $2$ \textit{vs.} $2$: $190.7$, $[131.0, 240.6]$) but not of Language ($-15.9$, $[-50.2, 10.1]$). Thus, while our model was able to qualitatively reproduce the influence of flanking vowels on epenthetic vowel quality for /u/, it was unable to reflect the fact that JP listeners perceive /u/ more often than BP listeners. 

There was also a main effect for Coronal $C_{1}$ ($-66.7$, $[-95.6, -39.5]$) but no interaction of this effect with Language ($40.2, [-28.0, 91.8]$); similarly to the perception data, this reflects an overall lower propensity for the model to `epenthesize' /u/ after coronal consonants. 
The triple interaction NSFV x Coronal $C_{1}$ x Language was significant for both "levels" of NSFV ($94.1, [19.9, 210.6]$, $525.8, [275.5, 666.1]$). Closer inspection suggests that this reflected the model's inability to predict higher percentages of /u/-responses by both BP and JP participants after coronal consonants when both flanking vowels were /u/. 

\subsection{Discussion}

Examining epenthetic vowel quality preferences by BP and JP speakers in a perception task, we corroborated previous findings (\cite{dupoux1999, dupoux2011}) that, like in loanword adaptations, the default epenthetic vowel during speech perception is /i/ for BP and /u/ for JP. Our acoustic analyses suggest that the choice of epenthetic vowel is acoustically driven. That is, in BP, /i/ is shorter and spectrally closer to the formant transitions in our stimuli than /u/ (and /o/), while the reverse holds in Japanese. As such, it may not be necessary to rely on phonological explanations of epenthetic vowel quality as in \cite{rose2006, uffmann2006}, were we to find that these are shared characteristics of default epenthetic vowels in a variety of languages. We also found an influence of flanking vowels on epenthetic vowel quality, similar to what was reported in \cite{dupoux2011}. Indeed, participants gave fewer default responses when the quality of the flanking vowels was in disagreement with the default choice, resulting in more "vowel copy" epenthesis (i.e. perceiving a vowel of the same quality as that of a flanking vowel). Furthermore, we found that this effect of flanking vowels is additive, as it is even more prominent when both flanking vowels are of the same quality. 

Interestingly, phonotactics did not influence JP participants' responses as may have been expected; while /o/ was almost exclusively perceived after coronal consonants, this was almost always the case for stimuli with $V_{1} = /a/$ (cf Figure~\ref{fig:per&model_responses}). In fact, for all combinations of flanking vowels, participants responded /i/ and/or /u/ more often than /o/ in coronal contexts, even though both /du/ and /di/ are phonotactically illegal sequences in JP. These results, which are reminiscent of previous work \cite{monahan2009, mattingley2015}, suggest that constraints on perception given by surface phonotactics can be overruled by constraints relative to matching input acoustics \cite{dupoux2011}. In fact, if this were not the case, novel sound sequences would have never arisen in JP loanwords (e.g. \textit{party} is adapted as \textipa{/pa:ti/}, not \textipa{/pa:tCi/}). 

Finally, we presented results from one exemplar model per language, based on productions by BP and JP participants, respectively. These models reproduced the major effects found in the perception experiment --- namely, the preferred epenthetic vowel (numerically), and some significant effects of language and flanking vowels --- although with a high level of noise. This noise level may be due to the relatively low number of tokens that were available as exemplars, the fact that the DTW procedure removes temporal cues (recall that we found that default vowels tend to be of shorter duration), and/or the fact that MFCC features do not appropriately capture speaker invariance.
We interpret the results as providing a proof of principle that some of the salient effects regarding perceptual epenthesis can be accounted for on purely acoustic grounds. Future research is needed to improve on the model, whose predictions deviated from the perceptual data on several counts (e.g., 6\% /o/-epenthesis for BP, but less than 1\% for JP; failure to produce more /u/-epenthesis for JP than BP). These improvements could involve more phonetically and/or temporally informed features (e.g., spectrotemporal representations \cite{chi2005}), state-of-the art large-scale approaches with HMM or DNN systems, or physiologically-inspired models of speech perception (e.g., based on cortical oscillations \cite{hyafil2015}). 

To conclude, a triple approach combining perception experiments, acoustic analyses, and modeling allows us to gain insight into the mechanisms underlying perceptual epenthesis, and, more generally, repairs of illegal phonological structure during speech perception.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Parlato_duration (Interspeech) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
{\color{blue}
\section{Predicting epenthetic vowel quality from acoustics II: It's about time!} \label{3-parlato-dur}

\subsection{Introduction}
%%% What do we need to address after previous experiment?

\subsection{Methods}
\subsubsection{Features}
% [KALDI] The overall MFCC computation is as follows:

%     Work out the number of frames in the file (typically 25 ms frames shifted by 10ms each time).
%     For each frame:
%         Extract the data, do optional dithering, preemphasis and dc offset removal, and multiply it by a windowing function (various options are supported here, e.g. Hamming)
%         Work out the energy at this point (if using log-energy not C0).
%         Do FFT and compute the power spectrum
%         Compute the energy in each mel bin; these are e.g. 23 triangular overlapping bins whose centers are equally spaced in the mel-frequency domain.
%         Compute the log of the energies and take the cosine transform, keeping as many coefficients as specified (e.g. 13)
%         Optionally do cepstral liftering; this is just a scaling of the coefficients, which ensures they have a reasonable range.

% The lower and upper cutoff of the frequency range covered by the triangular mel bins are controlled by the options –low-freq and –high-freq, which are usually set close to zero and the Nyquist frequency respectively, e.g. –low-freq=20 and –high-freq=7800 for 16kHz sampled speech.

In order to ensure feature compatibility with future experiments (due to differences in file formats), features were recalculated using the Kaldi speech recognition toolkit \cite{povey2011}, introducing slight changes regarding the parameters used in section \ref{2-parlato}. As in section \ref{2-parlato}, audio recordings of items used as stimuli in the perceptual experiment and those used for the acoustic analyses were converted into sequences of 39-dimensional feature vectors consisting of 13 Mel-frequency cepstral coefficients (MFCCs), with delta and delta-delta coefficients. In contrast to our previously used features, here our first coefficient did not correspond to the log of the total frame energy, but to the zeroth cepstral coefficient. We applied this changed purely due to the change in the tools used for computing the features. Since the zeroth coefficient corresponds to the sum of the log of the 40 mel values, it is roughly equivalent to the log energy. 
Additionally, we added 3 coefficients (and their corresponding delta and delta-delta coefficients) adding pitch information to our features: normalized-pitch, delta-pitch, voicing-feature. The final 48 coefficient values were standardised to each have zero-mean and unit-variance. The final 48 coefficient values were standardised to each have zero-mean and unit-variance within each speaker.  

\subsubsection{Classification}
For the simulation, we built a classifier that assigns any given template to one category in the set \{$V_{1}C_{1}iC_{2}V_{2}$, $V_{1}C_{1}oC_{2}V_{2}$, $V_{1}C_{1}uC_{2}V_{2}$\}, based on acoustic similarity to the exemplars recorded by native speakers of BP and JP.

\paragraph{Dynamic Time Warping}

As in section \ref{2-parlato}, we computed the optimal alignment between all $V_{1}C_{1}C_{2}V_{2}$ templates (e.g. /abgi/) and their corresponding $V_{1}C_{1}V_{3}C_{2}V_{2}$ epenthesized versions (e.g. /abigi/, /abogi/, /abugi/) using Dynamic Time Warping (DTW) \cite{sakoe1978} with the R package \textit{dtw} \cite{R-dtw}. In order to ensure that the resulting distances were not mainly influenced by spectral differences of flanking vowels $V_{1}$ and $V_{3}$, we only compared feature frames correpsonding to $C_{1}C_{2}$ clusters and $C_{1}V_{3}C_{2}$ sections. Note, however, that coarticulation cues from flanking vowels are expected to be present within the clusters. 

Concerning DTW specifics, in section \ref{2-parlato} we used the commonly used step pattern for which, at position $x_{i;j}$, the only possible steps are towards positions $x_{i+1;j}$ (horizontal step), $x_{i;j+j}$ (vertical step), or $x_{i+1;j+1}$ (diagonal step). In this default setting (named ``symmetric2'' in the R package \textit{dtw}), a diagonal step is twice as costly as a horizontal or vertical step, which favours template-query matches with compressions/stretching over more direct matches. Therefore, in this section we chose to opt for a step pattern with the same three possible steps as before (i.e., horizontal, vertical, diagonal), but for which diagonal steps cost as much as horizontal/vertical steps on the final DTW distance. Since distances obtained with this step pattern (``symmetric1'') cannot be normalised by being divided by the sum of the lengths of the template and query, we normalise by dividing the cummulative distance by the length of the optimal path.

From the DTW we extract two values per template-query combination: (1) $DTW_{dist}$, the normalised DTW distance between the template and the query, and (2) $DTW_{time}$, the proportion of non-diagonal steps taken in the optimal path. This latter value, which was not present in the previous version of the model, is an indicator of the proportion of time dilation and time compression that was required to match the template and the query.     

\paragraph{Similarity function}
We reprise the similarity function used in section \ref{2-parlato}, inspired by the exemplar-based generalized context model (GCM) detailed by \cite{nosofsky1992}, and make modifications to accommodate for the inclusion of the duration mismatch penalty $DTW_{time}$.
Our goal is to classify the $V_{1}C_{1}C_{2}V_{2}$ template into a category from the set of vowels \textipa{/i, o, u/}, through the similarity of the template to exemplars $V_{1}C_{1}iC_{2}V_{2}$, $V_{1}C_{1}oC_{2}V_{2}$, and $V_{1}C_{1}uC_{2}V_{2}$, respectively. We obtain $P(R_{J}|S_{i})$, the evidence favouring category $J$ given stimulus $i$, by averaging the similarity of said stimulus $i$ to all recorded exemplars of category $J$. Since we do not aim to introduce a language model to the exemplar model, as we want it to be based entirely on acoustics, we do not introduce a term for response bias for category J. All exemplars are weighted equally.   

{\color{red}
\begin{equation}
  % P(R_{J}|S_{i}) = \frac{b_{J} \sum_{j\epsilon C_{J}}M_{j} \eta_{ij}}{\sum_{k}b_{K} \sum_{k\epsilon C_{K}}M_{k} \eta_{ik}} %Nosofsky92
  P(R_{J}|S_{i}) = \frac{ \frac{1}{n_{J}} \sum_{j\epsilon C_{J}} \eta_{ij}}{\sum_{K} \frac{1}{n_{K}} \sum_{k\epsilon C_{K}} \eta_{ik}}
  \label{parlato-dur_eq_sim1}
\end{equation}
}
where $n_{J}$ is the number of exemplars of category $J$ and with $\eta$ defined as in equation \ref{parlato-dur_eq_sim2},

\begin{equation}
  \eta_{ij} = e^{-c \cdot d_{ij}}
  \label{parlato-dur_eq_sim2}
\end{equation}

where $c$ is a parameter determining the weight of $\eta_{ij}$ on classification. When $c = 0$, DTW is disregarded and all possible classification categories are equally probable. Higher values of $c$ result in higher sampling probabilities being given to items with smaller distance $\eta_{ij}$.

$\eta_{ij}$ is defined as in equation \ref{parlato-dur_eq_sim3}

\begin{equation}
  \eta_{ij} = w_{dist} \cdot DTW_{dist} + w_{time} \cdot DTW_{time}
  \label{parlato-dur_eq_sim3}
\end{equation}

where $w_{dist}$ and $w_{time}$ are weights given to $DTW_{dist}$ and $DTW_{time}$, respectively. Setting $w_{time} = 0$ gives an equivalent equation to the one used in section \ref{2-parlato}.

\subsubsection{Parameter estimation}
% Parameter $c$ was individually optimised for each language by performing leave-one-out cross-validation (maximum accuracy: $0.50$ with $c = 0.5$ for BP, and $0.63$ with $c = 2.2$ for JP; chance level at $0.33$).

We used grid search in order to optimise parameter $c$ with $w_{dist} = 1$, for each language. We classified all exemplars to a category within \textipa{/i, o, u/} in a leave-one-out cross-validation method. Namely, we assessed the accuracy in the classification of tokens with known labels, by measuring their respective similarity to all other exemplars and sampling the classification categories for each.
We assessed the optimality of parameter values based not only on mean classification accuracy, but on median classification accuracy. Indeed, as can be seen in figure \ref{}, while these two measures are positively correlated an increased performance at the level of median accuracy might not be obvious when inspecting mean accuracy alone. As a curious side note, increasing the value of $w_{time} = 1$ during cross-validation decreased classification accuracy.   

\begin{figure}[h!]
  \centering
  \begin{overpic}[clip, trim=0 0 0 0, page=1, width=0.9\linewidth]{chapter02/parlato_dur_spknormF.pdf}\end{overpic}
  \caption{\textit{}}
  \label{}
\end{figure}

\subsubsection{Data analysis}
Statistical analyses were performed with the R statistical software \cite{R-base}, using Markov chain Monte Carlo generalised linear mixed-models \cite{R-MCMCglmm, R-coda}. These Bayesian models sample coefficients from the posterior probability distribution conditioned on the data and given priors. We used priors that are standard for mixed-effects multinomial models. Model convergence was assessed by visual inspection of trace plots and the Gelman–Rubin convergence diagnostic \cite{gelman1992}, using four chains with different initialisations. Effects were considered statistically significant if the 95\% highest posterior density (HPD) interval estimated for the coefficient of interest did not include zero. 

In order to assess the influence of $V_{1}$ and $V_{2}$ (henceforth: flanking vowels) on epenthetic vowel quality (/i/ or /u/), we chose as fixed effects for our models \textsc{Language} (BP \textit{vs.} JP, sum contrast coded) and \textsc{Number of Same Flanking Vowels} (\textsc{NSFV}; considered as a continuous variable with values 0, 1, or 2 instead of a factor with 3 levels, in order to reduce the number of model parameters and promote convergence), as well as their interaction. As random effects we included \textsc{Cluster} and \textsc{Participant} when analysing data from the perceptual experiment, and \textsc{Cluster} when analysing data from the exemplar models. We also added random slopes for \textsc{Language} on \textsc{Cluster}, and \textsc{NSFV} on \textsc{Participant}. Please note that we re-analyse data from the perceptual experiment described in section \ref{2-parlato} because the statistical models used for the analyses in this section are not identical to those used in section \ref{2-parlato}. The change in models was motivated by a will to avoid coefficient inflation due to the sparsity of our data, as it was the case in section \ref{2-parlato}. 

\subsection{Results}
\subsubsection{Perception Experiment}
\paragraph{/i/-epenthesis}
\paragraph{/u/-epenthesis}

\subsubsection{Exemplar models without duration penalty}
\paragraph{/i/-epenthesis}
\paragraph{/u/-epenthesis}

\subsubsection{Exemplar models with duration penalty}
\paragraph{Setting the duration penalty}
\paragraph{/i/-epenthesis}
\paragraph{/u/-epenthesis}

\subsection{Discussion}
%% Summary of the results

%% Limitations 
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapter mini-discussion %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Summary and Discussion}

%% Summary %%

{\color{blue}Similarly to what has been previously observed \cite{dupoux1999, dehaene2000, dupoux2011, monahan2009, mattingley2015}[CITE], I find that BP and JP participants experience perceptual vowel epenthesis when presented auditory stimuli with illegal consonant clusters. For most cases, BP and JP participants insert what has been called a ``default'' epenthetic vowel, namely \textipa{/i/} and \textipa{/u/}, respectively. Confirming intuitions laid out by \cite{dupoux2011} and reminiscent of the {\color{red}P-map theory in \cite{steriade2001}}, acoustic measurements revealed that these vowels were, within their respective languages, acoustically minimal in that they were of shorter duration and closer in formant space to cluster transitions than other candidate vowels. \\

Also in agreement with previous observations \cite{dupoux2011}, I find that the quality of epenthetic vowel is modulated by the identity of flanking vowels: In {\color{red}section 2.2}, we see more \textipa{/u/}-epenthesis by BP participants with more \textipa{/u/} flanking vowels, and more \textipa{/i/}-epenthesis by JP participants with more \textipa{/i/} flanking vowels. Were these modulations of epenthetic vowel quality due to coarticulation cues contained in the consonant clusters or were they due to a phenomenon of vowel copy? \\

This question was tackled in {\color{red}section 2.1}, by assessing the perception of stimuli for which the identity of the flanking vowels was in disagreement with that of the coarticulation cues contained within consonant clusters. It was found that, while both flanking vowel and coarticulation influenced epenthetic vowel quality, it was the latter that was the most determinant. This is reflected by the results of the exemplar models evaluated in {\color{red}section 2.2}. Indeed, these models compared the acoustics of non-native $CC$ clusters to native $CVC$ exemplars, in order to determine the quality of the vowel to be epenthesized. And while they were unable to mimic default vowel epenthesis, they were able to reproduce quality modulations due to neighbouring vowels. Yet, these models could not perform vowel copy in a way other than by exploiting coarticulation remnants within the clusters. \\             

Concerning the models' failure to reproduce language-specific default epenthetic vowels, it is difficult to derive the conclusion that acoustics do not have a role in determining default epenthetic vowel quality. Indeed, as previously stated, our proof of concept exemplar model is very limited, as it performs pure acoustic matching between queries and a template without taking (vowel) duration into consideration, and lacking any sort of speaker normalisation. \\

Adding to these concerns, it is important to add that the model supposes the existence of {\color{red}multiphonemic} exemplars to which the non-native input is compared to. Leaving aside the fact that the use of exemplar representations during speech perception may be controversial, an important side-effect of exemplar-based models is that they are unable to model lack of epenthesis. Yet we saw in both {\color{red}sections 2.1 and 2.2} that participants did choose the ``no epenthesis'' options {\color{red}in several instances}.  \\

As such, we will now focus on perception models that are flexible enough to also output illegal structures, as our participants do. And, most importantly, the following models shall evaluate epenthetic vowel quality without ignoring the role of phonology (e.g., phonotactics) on misperception of non-native clusters. They must therefore incorporate statistics relative to the frequencies of phonemes and their structural {\color{red}arrangements}. \\

As discussed in {\color{red} section 2.1}, ours and \cite{dupoux2011} results are better aligned with one-step theories of non-native speech perception than with two-step theories. Indeed, the influence of acoustic details on epenthetic vowel quality would be lost if epenthesis occurred after an initial categorisation step; computation of the optimal output must incorporate acoustics and phonotactics in a unique step. In the following sections we will be switching from a one-step DTW-based exemplar model of non-native speech perception to more elaborate one-step Hidden Markov Models (HMM) that do not have the limitations listed above.}