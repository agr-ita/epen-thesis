%% Summary (how does it answer to the issues mentioned in the introduction? How does it not?) + future avenues

In this thesis, we investigated the mechanisms underlying perceptual vowel epenthesis, by combining experimental and modelling approaches. We specifically focused on the processing steps underlying vowel epenthesis during perception, and the acoustic, phonetic, and phonological factors influencing vowel epenthesis. All proposals in the two-step and one-step subgroups of theories accept that these multiple factors may explain the phenomenon of vowel epenthesis. It is in how these factors are weighted and integrated that lie the differences between the two families of theories.

Two-step theories posit that the epenthetic vowel is inserted by the phonological grammar after segment categorisation has been performed, while one-step theories propose that all influencing factors are integrated simultaneously in a probabilistic manner. As of now, it is difficult to formally compare these two hypotheses, due to lack of data that allows to disentangle them, but mostly because of the lack of quantitative model implementations of the theories that would allow us to generate detailed predictions, to be compared to experimental data.

In this thesis, we contributed to filling this gap by providing more experimental data and by developing quantitative models that are implementations of one-step theories. Two such models were developed: an exemplar-based model that compares nonnative input to minimally different native exemplars stored in memory (Chapter 2), and a speech recogniser that transcribes speech without relying on exemplars, but relying on models of phonemes instead (Chapter 3). \\    

In particular, we focused on two main questions:
\begin{enumerate}
\item Is perceptual vowel epenthesis a one-step or two-step process?
\item How does a computational implementation of a one-step proposal fare when quantitatively and qualitatively compared to behavioural results? 
\end{enumerate}

In Chapter 2, we investigated the role of acoustics in determining epenthetic vowel quality in cases where the epenthesized vowel is of the same quality as its neighbours, as opposed to attributing this phenomenon to a phonological process such as flanking vowel copy. We specifically examined how coarticulation cues present in speech items, either naturally or by splicing, modulated the quality of epenthetic vowels perceived by Brazilian Portuguese and Japanese listeners. In the case of spliced items, we were able to tease apart the individual contributions of acoustic/phonetic factors on the one hand, and phonological factors on the other hand. Based on results from two identification experiments, we found that participants' response patterns could be better explained by variations in coarticulation, with only a small contribution from flanking vowels. We were able to confirm the importance of acoustic detail on epenthetic vowel quality by simulating the behavioural experiments with exemplar-based models of perception. These models only had access to acoustic information and were able to reproduce modulations of epenthetic vowel quality observed in human results. These results were in support of one-step models of nonnative speech perception, in which the acoustic match and sequence match between the nonnative stimulus and the native percept are optimised simultaneously. On the contrary, two-step models in which sequence match is evaluated after an initial categorisation step, are unable to account for acoustic cues modulating epenthetic vowel quality.    \\


In Chapter 3, given the evidence in the previous chapter, we turned to evaluating one-step models specifically. To do so, we recruited tools from the field of speech engineering and automatic speech recognition (ASR). Namely, we built an implementation of a ``reverse inference'' one-step proposal (\cite{wilson2013}) by using HMM-GMM speech recognizers. These systems are composed of two independent modules: the acoustic model and the language model, which provide the computations necessary to retrieve the acoustic match and sequence match of a speech input and possible parses, respectively. The optimal transcription can be found by combining the two in a one-step optimisation process.
We proposed a novel way of testing such ASR models in an identification task analogous to those used when probing perceptual vowel epenthesis in human participants. We do this by building language models for decoding that are constrained to only output the response options given to human participants in the forced choice identification task. Depending on the type of phonotactic model that is used, different options may have different weights, i.e., different probabilities. The model outputs responses by integrating the acoustic probabilities given by its acoustic model, and the probabilities found in the constrained forced choice language model.

Considering the findings from the previous chapter, we used this method to evaluate the predictive power of the acoustic model. Following the result that the ASR system with a null model better approximated human responses than ASR systems with more phonotactically elaborate language models, we assessed whether the speech recogniser with the null language model was able to mirror effects of variation in epenthesis. The underlying hypothesis being that the acoustic model may be sufficient to explain these effects, without contributions of more abstract phonological processes. We found that the output from our model was, however, not perfect; the model was not able to faithfully reproduce certain effects that are of acoustic/phonetic origin such as nonnative vowel assimilation, and modulations of the epenthetic vowel quality by coarticulation that the exemplar-based model was able to capture. It was also unable to account for variations of rates of epenthesis due to the syllabic position of the clusters. Importantly, the effects that the model was able to reproduce (e.g., modulations of the epenthetic vowel quality by \textipa{/i/} coarticulation) were of lower magnitude, compared to their human equivalents. 

These results from using relatively simple ASR models suggest that the acoustic model component of the ASR system must be enhanced in order to better evaluate which effects are due to acoustics and which ones may be due to phonological processes.
The use of language models should also be explored further by testing language models that incorporate concepts of higher level than bigram transition probabilities.
Connectionist models made available by deep learning implementations offer the opportunity to enhance models at the level of both the acoustic and language models, and are therefore a promising avenue of future research, in spite of their need for large volumes of data for training. Recall, however, that we highlighted that the quality of the data used for training should also be improved, if possible, even when used more elaborate ASR models.

Aside from improving our model implementation with more state-of-the-art ASR systems, future work should involve a combination of various psycholinguistic paradigms, to ensure that effects observed in both human and model data are not solely due to the specific task used. While we focused on modelling identification tasks (i.e., \textit{n}-forced choice paradigms), it is also possible to evaluate ASR models using non-metalinguistic tasks, such as the ABX discrimination task \cite{schatz2018}. Testing as many combinations of parameters (e.g., acoustic features, model architectures, input data, experimental paradigms, ...), in a search of replicability, is a necessary step towards elucidating the mechanisms underlying speech perception.\\

A modelling approach combined with the availability of behavioural data, such as how it was presented in this thesis, allows us to quantitatively and qualitatively test well-defined theories of nonnative speech perception. Importantly, the same model architecture can be used to study the phenomenon of interest (here: vowel epenthesis) in a crosslinguistic fashion. Not only by cross-referencing to existing behavioural data, but also by allowing to derive new predictions about nonnative speech perception. Moreover, our modelling approach can be easily adapted and extended to fields outside of the field of nonnative speech perception. We encourage future research to combine experimental and modelling approaches in order to evaluate mathematically- and/or algorithmically-defined psycholinguistic theories. 
