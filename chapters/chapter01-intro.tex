%%% TO-DO %%%
% - [X] Keep same POV throughout sentences 
% - [X] 1 sentence == 1 idea. Expand; don't be afraid to write more text!
% - [ ] Check paper comments (Emm 20/07)
% - [X] Paragraph 3: "There are multiple proposals. Need to better define them/have precise proposals to test empirically. Here: we take one of the proposals and put it to a test with a computational model"
% - [ ] STRUCTURE
%     - [ ] EITHER: 1) Perceptual 2) Similar phenomenon in loanwords
%     - [ ] OR: 1) Loanwords 2) Perception (->1 maybe explains loanwords) 3) Here: dealing with perception
% - [ ] SEPARER PERCEPTION AND LOANWORDS (including what is input and output in each). Lw = source of inspiration + data (allows predictions for perception) 
% - [ ] Careful not to confuse perceptual task with "individual loanword task"
% - [ ] Préciser qu'on va tester spécifiquement les théories one step

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Beginning from the time spent in her mother's womb, a baby is exposed to sounds and, importantly, she is exposed to speech. Initially a ``universal listener'', in her early months she is initially able to discriminate a wide variety of sounds [CITE]. However, as she is exposed to only one or a few languages that are spoken around her, she progressively loses the ``universal listener'' title. Indeed, through this exposure, her perceptual system progressively becomes attuned to sounds and structures useful for decoding what will progressively become her native language(s) [CITE Werker].

That is, at around 10 months of age, the infant's perceptual system shows signs of becoming optimised for receiving and processing native input.
On one hand, a native phonemic inventory is established. Phonemes are generally as the smallest phonetic units capable of conveying a lexical distinction in a language. It is therefore essential for the infant to be able to notice when two different acoustic signals correspond to the same or different phonemes, in order to properly access lexical meaning. For this to happen, her perceptual system partitions the acoustic space into areas corresponding to the phonemes relevant for her native language [CITE]. 

On the other hand, the infant also becomes aware of which phoneme combinations occur in the language and which ones do not [CITE Saffran, ...]. In particular, she progressively acquires the phonotactics for her native language, namely, the constraints determining what constitutes well-formed native sound combinations [CITE: Jusczyk, Pisoni?...]. This is useful, for instance, when trying to find word boundaries in fluent speech, as it is more probable for a rare phoneme combination to occur between words than within words [CITE]. 

Through the optimisation process that results in the acquisition of the nativephoneme inventory and native phonotactics, the infant's perceptual system becomes specialised in her native language, allowing her to better tackle problemes such as word learning.  

Most of us have been that universal listener baby that then became a perceptually attuned infant. And while this perceptual attunement allows us to communicate efficiently in our native language, issues arise when we attempt to acquire nonnative languages as adults.
Nonnative speech is processed by a perceptual system that has been optimised for our native language. It is therefore processed according to segmental and suprasegmental inventories, and phonotactics that do not match those intended by the speech source. 
This often results in nonnative speech being misperceived; phonemes and prosodic elements might be replaced (assimilation) or deleted (ellipsis). Additional phonemes might even be inserted (epenthesis).

It seems to be generally accepted in the loanword adaptation and nonnative speech perception literatures that misperceptions of nonnative speech result from minimal modifications of the original speech. However, there are multiple proposals relating to the exact nature of these modifications. For instance, are these phonetically-minimal? Phonologically-minimal?    
% - [ ] Paragraph 3: "There are multiple proposals. Need to better define them/have precise proposals to test empirically. Here: we take one of the proposals and put it to a test with a computational model"

It is my belief that the various proposals put forward must be formally defined in order to be tested empirically.  
In this dissertation, I select one of the proposals advanced by the psycholinguistics literature, namely the perception-based reverse inference models of nonnative speech perception, and test a proof-of-concept computational implementations. 
%For the purpose of this work, the computational models are issued from the field of automatic speech recognition (ASR). 
I present various methodologies for qualitatively and quantitatively evaluating the reverse inference proposal, focusing on the phenomenon of perceptual vowel epenthesis. Following on [CITE peperkamp], the data arising from the computational models is compared to data from psycholinguistics experiments. In these, nonnative speech perception is evaluated using psycholinguistics paradigms which tap onto online (i.e., real-time, individual) perception of nonwords, in order to reduce the influence of confounds such as orthography and semantics.
In other words, I subject the proposed computational models to tasks analogous to those completed by human participants and analyse their behaviour both quantitatively and qualitatively. Do we find perception-based mechanisms to be necessary to predict perceptual vowel epenthesis? If so, do they suffice? 

% - [ ] OR: 1) Loanwords 2) Perception (->1 maybe explains loanwords) 3) Here: dealing with perception
\section{Vowel epenthesis in loanword adaptations}
\section{Perceptual vowel epenthesis}
\section{Processing steps in perceptual vowel epenthesis}
\section{Justifying the modelling approach}
\epigraph{... But why make models?}{\textit{Derek Zoolander, probably.}}
Quantitative testing $~$

Suggestion Thomas: ``au-delà de permettre des tests quantitatifs, ça peut être bénéfique simplement pour formuler et réfléchir aux théories (less vague/ambiguous than verbal theories, forces rigorous definitions and precise hypothesis formulation, makes it easier to identify where theories fundamentally differs and where there is only shallow differences).''
\section{Outline of this thesis}
%%%%%%%


{\color{red}
\section{Perceptual vowel epenthesis [main]}

As mentioned above epenthesis is the phenomenon in which a sound that was not initially present in the input is inserted and surfaces in the output\footnote{Depending on context, the word ``epenthesis'' can refer to the addition of any sound (consonant, vowel ...) in different situations such as online perception, online production, diachronic lexical changes, etc. For the purpose of this thesis, however, we will specifically use the word ``epenthesis'' to refer to perceptual vowel epenthesis, unless stated otherwise.}. As such, when listeners experience perceptual vowel epenthesis, they hallucinate vowels not initially present in the input. In the cases studied in this work, this happens in order to break phonotactically illegal clusters present in the input. For instance, in Japanese most consonant clusters\footnote{Consonant clusters can only be geminates or a nasal followed by another consonant.}, such as \textipa{/bz/}, are phonotactically illegal. When hearing nonwords containing these clusters, such as \textipa{/ebzo/}, Japanese listeners may hallucinate an epenthetic \textipa{/u/}\footnote{A more faithful phonetic transcription of the vowel is \textipa{[W]} but following previous work the phonological notation \textipa{/u/} will be used in the remainder of the thesis.} within the cluster, yielding \textipa{/ebuzo/} as the output percept \cite{dupoux1999}. Epenthesis of \textipa{/u/} by Japanese listeners is not only evident in their behaviour but also in their brain responses; they have difficulties differentiating the clusters produced by a French speaker from their epenthesized counterparts (e.g., \textipa{/ebzo/} \textit{vs.} \textipa{/ebuzo/}) while also showing different event-related potentials compared to native French speakers \cite{dehaene2000}.
Epenthesis has also been attested in languages other than Japanese [cite: Dupoux (1999), Dehaene (2001), Dupoux (2001), Monahan (2009), Dupoux (2011), Mattingley (2015)]; it has been studied in Korean [cite: de Jong \& Park (2012), Durvasula (2015), Shin \& Iverson (2011)], Brazilian Portuguese [cite: Dupoux (2011)], Spanish [cite: Hallé (2014)], English [cite: Berent (multi), Davidson], Mandarin Chinese [cite: Durvasula (2018)], and Cantonese [cite: Silverman (1992)?]. 


%Epenthesis fossils: loanwords \\
%  - loanwords + online: phonotactics' mismatch $\rightarrow$ epenthesis/deletions

\section{Input representations of nonnative speech [what]}

Perceptual vowel epenthesis has been the subject of research mainly in two fields: loanword phonology and psycholinguistics. The former focuses on how words of nonnative origin have been adapted when being imported to the native language; this is mostly a diachronic process involving multiple individuals and possibly various methods of word transmission (e.g., through written materials, orally, etc), with the assumption that words are introduced by highly proefficient speakers of the nonnative language. In contrast, the psycholinguistic approach focuses on online perception and, while data from multiple participants is collected, the modifications observed on the output of perception are assumed to be individual in nature. Participants are not expect to be proficient in the nonnative language, which minimises the influence of linguistic knowledge and orthography. Considering these differences, it comes as no surprise that, while both seem to agree that the output is the closest possible native match to the nonnative input, the two approaches hypothesise different mechanisms to account for perceptual vowel epenthesis. 

In particular, there is the question of how the nonnative input is represented and processed in the minds of the listeners. With a little simplification, authors from the loanword literature advance the hypothesis that are more phonological and abstract in nature. The adapted (epenthetic) output corresponds to the best match to the input after candidate matches are passed through a grammatical filter, comprising faithfulness and markedness constraints arranged in a certain order that may or may not be compatible with native sets of constraints [cite: Hyman (1970), Lovins (1975), Yip (1993), Jacobs \& Gussenhoven (2000), Shinohara (2004)]. As mentioned previously, the initial importers of the nonnative words are assumed to be highly proficient in the target language (e.g., bilinguals); as such, in this view a faithful underlying representation of the input only becomes adapted when the grammar computes a surface representation from said underlying form (e.g., during production).      


\begin{itemize}
  \item
  \begin{itemize}
  \item Phonological approach \\
    - La Charité \& Paradis (2005): Feature-based proximity. Loanwords introduced by bilinguals, who can manipulate and compare L1 and L2 systems. \\
  \item Acoustic/phonetic \\
    - Psycholinguistic theories of nonnative speech perception: Best (1995), Kuhl (1995), / Flege / Burnham /  
    - Peperkamp \& Dupoux (2003): phonetically minimal modification mapping by phonetic decoding module, and underlying representation is derived from percept by the phonological decoding module (i.e., it's unfaithful to nonnative UR). The phonetic decoding module takes into account segmental, suprasegmental, and syllabic inventory $\rightarrow$ find phonetically minimal modification \\
    - Steriade (2001): P-map
  \item Shin \& Iverson (2011): correlation between \%epenth and vowel discrimination.   
  \item Articulatory \\
    - activation of motor cortex areas during perception + perception biases trigger by disruption of motor cortex activity with TMS (D'Ausilio, Berent (2015), etc)
  \item Gestures \\
    - Browman \& Goldstein (1980s): Articulatory Phonology; dynamic gestures as units, developing in space at time (as opposed to the static segment). Sounds correspond to constellation of gestures. Allows to explain gradient effects.  
    - Zhao \& Berent (2018): Epenthesis from read stimuli (i.e., no acoustic input) \\
    - Best \& Tyler (2007): "PAM posits that perceivers extract invariants about *articulatory gestures* from the speech signal, rather than forming categories from acoustic-phonetic cues"
  \end{itemize}
\end{itemize}

\section{Adding to the mix}  
 
\begin{itemize}
\item Structural information (phonotactics: surface, syllabic) \\
  Kabak \& Idsardi (2007): "best working hypothesis is that violations involving syllable structure instead of consonantal contact affect perception, and neither nasalization nor lateralization have any basis in perception."
  \item Phonological rules / constraints
  \item Lexical influx/phone frequency (probabilistic info) \\
    - Kabak \& Idsardi (2007): "a phonological influence of L1 phonotactic knowledge, rather than an effect of frequency, plays a primary role in explaining Korean groups’ performance." \\
    - Dupoux (2001): Prelexical process 

  \item Orthography \\
    - Vendelin \& Peperkamp (2006): Cf interaction of orthography on vowel adaptation \\ 
    - Daland (2015): ``Strong evidence that Korean listeners relied on the English orthography in selecting the korean vowel adaptation.''; Perceptual Uncertainty Hypothesis: "Orthography is most likely to constrain loanword adaptation in cases when it is not fully determined by perception/phonology alone."
    
\end{itemize}

\section{Processing workflow}
\begin{itemize}
\item One-step vs. Two-step
  \begin{itemize}
  \item Two-step
      \begin{itemize}
        \item Silverman (1992): From evidence of Cantonese loans from English, model with 2 scansions: (1) Perceptual level representation $\rightarrow$ preliminary segmental + prosodic structure. (2) Operation level representation $\rightarrow$ final form. (Yet Silverman seemed to assume that loanwords are faithful to online percepts).
        \item Monahan (2009):
        \item Berent (2007): 
      \end{itemize}
  \item One-step
      \begin{itemize}
         \item Dupoux (2011): simultaneous optimisation of the acoustic match and the sequence match.
         \item Wilson (2014?): Bayesian approach where task is P(phon|acoustics) \~ P(X|phon)P(phon), with P(phon) being the phonotactic acceptability 
         \item Durvasula (2015): as Dupoux (2011) \& Wilson \& Davidson (2013), process of reverse inference, but including access to native phonological rules to infer pseudo-underlying forms of the nonnative input.
      \end{itemize}  
  \end{itemize}
\item early process (input syst) vs late process (orthography, differences in production ...)
  \begin{itemize}
     \item Dehaene (2001): "However, the condition effect observed in Japanese during the second response suggests that some information about the input could be recovered from other processing systems";
  \end{itemize}  
\end{itemize}
}



