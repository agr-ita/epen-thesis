%%% TO-DO %%%
%
% - [ ] Section about nonnative misperceptions
% - [ ] Clarify loanwords
% - [ ] Structure change
% - [ ] ABX IDS/ADS in "Justifying the modelling approach"



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\color{red}[Sharon]: I automatically started giving detailed comments, but suddenly realize: why on earth begin your thesis with a story on infants and early acquisition? You should talk about the difficulties adults have perceiving (and if you wish producing) foreign sounds and sound structures! An anecdote would be ok (but not necessary), and then explain that our perception is optimized for native language processing and - if you wish! - that this is put in place during the first year of life.}



Beginning from the time spent in her mother's womb, a baby is exposed to sounds and, importantly, to speech. Initially a ``universal listener'', in her early months she is able to discriminate a wide variety of sounds [CITE]. However, as she is exposed to only one or a few languages that are spoken around her, she progressively loses the ``universal listener'' title. Indeed, through this exposure, her perceptual system progressively becomes attuned to sounds and structures useful for decoding her native language(s) [CITE Werker].

That is, at around 10 months of age, the infant's perceptual system shows signs of becoming optimised for receiving and processing native input.
On the one hand, a native phonemic and suprasegmental inventories are established. Suprasegments are acoustic effects spanning more than one phoneme, such as stress, tone, pitch. But what are phonemes? 
Phonemes, also refer to as segments, are generally defined as the smallest phonetic units capable of conveying a lexical distinction in a language. It is therefore essential for the infant to be able to notice when two different acoustic signals correspond to the same or different phonemes, in order to properly access lexical meaning. For this to happen, her perceptual system partitions the acoustic space into areas corresponding to the phonemes relevant for her native language [CITE]. 

On the other hand, the infant also becomes aware of which phoneme combinations occur in the language and which ones do not [CITE Saffran, ...]. In particular, she progressively acquires the phonotactics for her native language, namely, the constraints determining what constitutes well-formed\footnote{Well-formedness can be defined within a probabilistic framework, but also with hard, binary constraints, or even a combination of the two types of processes. I do not dwell on the subtleties existing between the two in this work, however the interested reader is invited to consult the extensive review in [CITE: Lentz2011].} native sound combinations within words and syllables [CITE: Jusczyk, Pisoni?...]. This is useful, for instance, when trying to find word boundaries in fluent speech, as it is more probable for a rare phoneme combination to occur between words than within words [CITE]. 

Through the optimisation process that results in the acquisition of the native phoneme inventory, native suprasegmentals, and native phonotactics, the infant's perceptual system becomes specialised in her native language, allowing her to better tackle problemes such as word learning.  

Years later, the infant is now an adult with an attuned perceptual system. 
And while this perceptual attunement allows her to communicate efficiently in her native language, issues arise when she now attempts to acquire nonnative languages.
Nonnative speech is processed by her perceptual system, which has been optimised for her native language. The nonnative speech is therefore processed according to her native segmental and suprasegmental inventories, and phonotactics, which do not match those intended by the speech source. 
For our adult listener this will often result in nonnative speech being misperceived; phonemes and prosodic elements might be replaced (assimilation) or deleted (ellipsis). Additional phonemes might even be inserted (epenthesis).

It seems to be generally accepted in the nonnative speech perception literature that misperceptions of nonnative speech result from minimal modifications of the original speech. However, there are multiple proposals relating to the exact nature of these modifications. For instance, are these phonetically-minimal? Phonologically-minimal? At what perceptual stage do they apply? 

Various proposals of mechanisms underlying nonnative speech perception have been put forward; however, many lack formal definition that allow them to be tested empirically.  
In this dissertation, I select one of the proposals advanced by the psycholinguistics literature, namely the perception-based reverse inference models of nonnative speech perception \cite{dupoux2011, wilson2014}, and test a proof-of-concept computational implementation. 
I present various methodologies for qualitatively and quantitatively evaluating the reverse inference proposal, focusing on the phenomenon of perceptual vowel epenthesis.
{\color{red}[Sharon]: ``focus on epenthesis almost goes unnoticed and it's really important!''}
Following on [CITE Peperkamp], the data arising from the computational models is compared to data from psycholinguistics experiments. In these, nonnative speech perception is evaluated using psycholinguistics paradigms which tap onto online (i.e., real-time, individual) perception of nonwords, in order to reduce the influence of confounds such as orthography and semantics.
In other words, I subject the proposed computational models to tasks analogous to those completed by human participants and analyse their behaviour both quantitatively and qualitatively. Do we find perception-based mechanisms to be necessary to predict perceptual vowel epenthesis? If so, do they suffice? 

In order to investigate the underlying mechanisms of nonnative speech perception, we are required to refer to work in two relevant fields, loanword adaptations and nonnative misperceptions.
The former focuses on how words from a source language are modified when introduced to a borrowing language. Rather embedded in the field of theoretical linguistics, this literature offers an indirect window to perception, as loanwords are the product of various complex language transmission phenomena. 
On the other hand, the experimentally inclined literature of psycholinguistics on nonnative speech perception offers more direct data for undestanding misperceptions. However, data may be less readily available than for loanwords. I will now present both literatures, focusing on various mechanisms that have been proposed to explain the phenomenon of vowel epenthesis within both fields.  

{\color{red}[Sharon]: I'd change the order: psycholing. first, and then - because of lack of data - loanwords (which otherwise come out of the blue) \\

Alternatively, if you want to start with loanwords, you should introduce them in the very first paragraph of the intro, which should then go something like this: \\
- we have an accent in L2 \\ 
- we adapt loanwords \\
- both are production phenomena that are at least in part due to speech perception}

\section{Vowel epenthesis in loanword adaptations}
The phenomenon of vowel epenthesis has been studied in the context of loanword adaptations, namely the modification of words from a source language when they are introduced to a borrowing language. Consider the bold vowels in the following examples:
\begin{itemize}
  \item English ``strike'' \textipa{/st\*raIk/} $\rightarrow$ Japanese \textipa{/s\textbf{u}t\textbf{o}raik\textbf{u}/}
  \item French ``baguette'' \textipa{/bagEt/} $\rightarrow$ Japanese \textipa{/baget:\textbf{o}/} %\begin{CJK}{UTF8}{goth}バゲット\end{CJK} \textipa{//} 
  \item English ``snob'' \textipa{/sn6b/} $\rightarrow$ Spanish \textipa{/\textbf{e}snob/}
  \end{itemize}
  
In this context, vowel epenthesis consists in the insertion of a vowel in the (borrowing) surface form of a word that did not contain said vowel in the underlying representation in the source language. Epenthesis often occurs when the introduced word does not respect the phonotactics of the borrowing language (e.g., illegal consonant clusters, illegal syllabification).
The foreign word is imported to the borrowing language in a diachronic process involving multiple individuals and possibly various methods of word transmission (e.g., through written materials, orally, etc). Additionally, adaptations can be influenced by orthography, when available [CITE Daland 2015; Vendelin\&Ppkmp, Ito?]. In this framework the assumption often is that words are introduced to the borrowing language by highly proficient speakers of the source language that are, therefore, able to access a faithful underlying representation of the source word. 

Concerning the question of how the nonnative source word is transformed into the adapted loanword, authors from the loanword literature advance the hypothesis that the underlying mechanisms are phonological and abstract in nature.


{\color{red}Hyman (1970), Lovins (1975), : pre-OT}

For instance, in a grammar-based view, the adapted loanword corresponds to the best match to the source word after candidate adaptations are passed through a grammatical filter  [CITE: Yip (1993), Jacobs \& Gussenhoven (2000), Shinohara (2004)]. In this case, {\color{red}[TODO; unclear] the grammar comprises faithfulness and markedness constraints arranged in a certain order, with some authors suggesting that some modifications might be more degrading that others \cite{steriade2001}. How constraints are arranged may or may not be compatible with how native sets of constraints are ordered.} It is assumed that the underlying representation of the source word is accessible and is used in the derivation of the adapted loanword. As such, the faithful underlying representation only becomes adapted when the grammar computes a surface representation from said underlying form (e.g., during production).   \\

Another similar mechanism was proposed by [CITE La Charité \& Paradis (2005)], where adaptations are based on minimal featural changes. The source word is adapted by highly proficient bilinguals, who can manipulate and compare the phonological systems of both the source and the borrowing languages. In this case, adaptation consists in these highly proficient bilinguals choosing the modifications of the source word that result in the least featural changes between the source adaptation and the resulting loanword.  

In many proposals, the role of perception has been assumed to be minimal, or at least secondary, in loanword adaptation [CITE e.g., LaChParadis1997]. However, this view is far from being a consensus. For instance, as briefly mentioned earlier, \cite{steriade2001} proposed that some grammar-based modifications resulted in more perceptually-salient modifications of the source word, resulting in a greater amounts of degradation.
Also, [CITE silverman1992] proposed his multiple scansion theory of loanword adaptation. In this theory, the underlying representation in the borrowing language is retrieved from a phonetic, possibly acoustic, form of the source word. In a first step, a perceptual-level representation is established, where the underlying representation is built with preliminary segmental and prosodic structure. It is only at a second step, at the operational level, that the phonology of the borrowing language is applied to the word (e.g., through a grammatical filter), resulting in modifications such as vowel epenthesis, when necessary. For similar proposals, see [CITE Kenstowicz 2001/2003, KenstowiczSuchato, Yip1993/2006].  

{\color{red}Alternative structure: Change to (1) Purely phonological and (2) Perceptual}


\section{Perceptual vowel epenthesis}

In the late nineties various theories of nonnative speech perception [CITE Best1995, Kuhl1995] and second language phoneme acquisition [Flege1995] surfaced in the psycholinguistics literature. There seemed to be an overlap between the observed nonnative speech misperceptions and patterns observed in loanwords; may perception directly account for loanword adaptation?   
It is in this context that appeared proposals such as that of [CITE PeperkampDupoux2003], which put greater emphasis on the role of misperception on loanword adaptation. The proposal being that, when perceiving nonnative input, a phonetic decoding module takes into account segmental, suprasegmental, and syllabic inventories of the native language in order to derive a phonetically-minimally modified representation\footnote{Whether this representation is acoustic, articulatory [CITE cf Berent2015], and/or gestural [CITE: BrowmanGoldstein, Best1995, BestTyler2007] in nature is not discussed here.} of the acoustic input. It is this misperceived version that is then converted into an underlying representation by a phonological decoding module; this cemented underlying representation is unfaithful with respect to the original underlying representation in the nonnative language.  
% As mentioned above epenthesis is the phenomenon in which a sound that was not initially present in the input is inserted and surfaces in the output\footnote{Depending on context, the word ``epenthesis'' can refer to the addition of any sound (consonant, vowel ...) in different situations such as online perception, online production, diachronic lexical changes, etc. For the purpose of this thesis, however, we will specifically use the word ``epenthesis'' to refer to perceptual vowel epenthesis, unless stated otherwise.}.
In this context, when listeners experience perceptual vowel epenthesis, they hallucinate vowels not initially present in the nonnative speech. In the cases studied in this work, this happens as a way to break phonotactically illegal clusters. For instance, in Japanese most consonant clusters%\footnote{Consonant clusters can only be geminates or a nasal followed by another consonant.}
, such as \textipa{/bz/}, are phonotactically illegal. When hearing nonwords containing these clusters, such as \textipa{/ebzo/}, Japanese listeners may hallucinate an epenthetic \textipa{/u/}\footnote{A more accurate phonetic transcription of the unrounded high back vowel used in Japanese is \textipa{[W]} but, following previous work, the phonological notation \textipa{/u/} will be used in the remainder of the thesis.} within the cluster, yielding \textipa{/ebuzo/} as the percept \cite{dupoux1999}. Epenthesis of \textipa{/u/} by Japanese listeners is not only evident in their behaviour but also in their brain responses; they have difficulties differentiating the clusters produced by a French speaker from their epenthesized counterparts (e.g., \textipa{/ebzo/} \textit{vs.} \textipa{/ebuzo/}) while also showing different event-related potentials compared to native French speakers. The fact that Japanese listeners fail to show sign of MMN (mismatch negativity) in the EEG signal attests that the process of epenthesis occurs early in the process of perception \cite{dehaene2000}. Importantly, experimental data also suggests that epenthesis is a pre-lexical process happening early in speech perception \cite{dupoux2001}.
Epenthesis has also been attested in languages other than Japanese [cite: Dupoux (1999), Dehaene-Lambertz (2000), Dupoux (2001), Monahan (2009), Dupoux (2011), Mattingley (2015)]; it has also been studied in languages such as Korean [cite: de Jong \& Park (2012), Durvasula (2015), Shin \& Iverson (2011)], Brazilian Portuguese [cite: Dupoux (2011)], Spanish [cite: Hallé (2014), Daland], English [cite: Berent (multi), Davidson], and Mandarin Chinese [cite: Durvasula (2018)].

While research on perceptual vowel epenthesis uses the literature on loanword adaptation as a a source of inspiration and a source of informed predictions, it is important to note that the phenomenon of vowel epenthesis is not defined equally in both fields. Remember that loanword adaptation is a diachronic process, involving complex interactions between several groups of individuals, with varying degrees of source language fluency. 
In contrast, the psycholinguistic approach focuses on online perception and, while data from multiple participants is collected, the modifications observed on the output of perception are assumed to occur at the level of the individual, as there is no interaction between participants. Participants are not expect to be proficient in the nonnative language, which minimises the influence of linguistic knowledge on misperceptions (e.g., orthography). 

%  - Shin \& Iverson (2011): correlation between \%epenth and vowel discrimination.   \\
% - Kabak \& Idsardi (2007): a phonological influence of L1 phonotactic knowledge, rather than an effect of frequency, plays a primary role in explaining KR groups performance."
%- Browman \& Goldstein (1980s): Articulatory Phonology; dynamic gestures as units, developing in space at time (as opposed to the static segment). Sounds correspond to constellation of gestures. Allows to explain gradient effects.  
%- Zhao \& Berent (2018): Epenthesis from read stimuli (i.e., no acoustic input) \\
%- Best \& Tyler (2007): "PAM posits that perceivers extract invariants about *articulatory gestures* from the speech signal, rather than forming categories from acoustic-phonetic cues"

\section{Processing steps in perceptual vowel epenthesis}

From now on we will focus on perceptual vowel epenthesis, referring to loanwords as a source of inspiration for experimental setups and as a source of informed predictions. Concerning the process of vowel epenthesis, we can identify two types of proposed pipelines that differ in the amount of processing steps that the nonnative input is subjected to during perception: these are two-step and one-step theories of nonnative speech perception, illustrated in Figure \label{ref:intro_12step}. While these names are somewhat transparent, we will now explain in more detail the differences between the two types of proposals.   

Reminiscent of Silverman's multiple scansion theory for loanword adaptations \cite{silverman1992}, two-step theories of nonnative speech perception divide the perception process in two stages. According to these proposals, the quality of the epenthetic vowel is determined by a language-specific grammar after an initial parsing of the nonnative input.
For \cite{berent2007}, the identity of the segments present in the nonnative input is retrieved in an initial step, yielding a \textit{phonetic form}. The native grammar then assesses the phonotactic legality of this phonetic form in a second step. If a phonotactic violation is found, the grammar, which combines both language-specific and universal components, repairs the phonetic form by inserting a vowel. The output of this final step is the \textit{phonological representation}.
Another proposal, that of \cite{monahan2009}, also consists in two steps, but with some differences. During the first step the identity of the segments in the input is retrieved and segments are grouped into syllables, following native phonotactics. Some syllables will contain indeterminate segments (e.g., \textipa{/ebzo/} will have been parsed as \textipa{/e.b}V\textipa{.zo/}). In a second step, the quality of the indeterminate segments, in this case the epenthetic vowel, is chosen amongst vowels that are of low sonority and can undergo devoicing. {\color{red}[Sharon]: ``explain low sonority and especially give background on vowel devoicing''}
The quality of the vowel might not be determined if an optimal match is not found.
The two proposals that we have summarised share the fact that the categorisation of the segments that are not the epenthetic vowel occurs in a first step and it is not modified during the second step, where the identity of the epenthetic vowel is determined.

\begin{figure}[htb!]
  \centering
  \begin{overpic}[page=1, width=0.9\linewidth]{chapter01-intro/12step}\end{overpic}
  \caption{\textit{Processing of the nonnative stimulus \textipa{/ebzo/} by Japanese listeners, according to two-step and one-step proposals for perceptual vowel epenthesis. {\color{red}[Sharon]: Add citations for reverse inference as well.}}}
  \label{fig:intro_12step}
\end{figure}

In contrast, with one-step proposals, authors such as \cite{dupoux2011} and \cite{wilson2013} argue that the identity of the epenthetic vowel is determined in the process of parsing the input, simultaneously to the categorisation of all other segments. The phonotactic legality of the input is therefore assessed at the same time as the categorisation happens. Notably, the input is not processed as a linear sequence of sounds; syllabic structure is taken into account during the parsing process \cite{kabak2007}.

\cite{wilson2013} qualify the process as a process of reverse inference within a Bayesian framework, where the perceptual system computes $P(w | X)$ the posterior probability of candidate percepts $w$ given the auditory input $X$. These are estimated, for each candidate percept, from the product of $P(X|w)$ the likelihood of the acoustics given the percept and $P(w)$ the prior probability of the percept, defined as its phonotactic acceptability. Mathematically, this can be formulated as in equation \ref{eq_onestep1}. Then, in a maximum \textit{a posteriori} (MAP) estimation scenario, the final percept $\widehat{w}$ corresponds to the percept with the highest posterior probability, as shown in equation \ref{eq_onestep2}. Alternatively, the final percept may be estimated by weighted sampling, where weights are defined by the posterior probabilities.     

\begin{equation}
  P(w | X) \propto P(X | w) \cdot P(w)
  \label{eq_onestep1}
\end{equation}

\begin{equation}
  \widehat{w} = \underset{w}{arg\,max} \left \{ P(X|w) \cdot P(w) \right \}
  \label{eq_onestep2}
\end{equation}

In other words, for one-step models, parsing becomes an optimisation problem where the optimal output is the one maximising the acoustic match to the input and the likelihood of the phonemic sequence in the native language. \cite{durvasula2015} adds to the aforementioned proposals by suggesting that listeners are decoding nonnative speech through a {\color{red}process of reverse inference that not only optimises the output according to phonetic representations and surface phonotactics, but also according to native phonological alternations (i.e., mappings between underlying and surface representations) [Sharon]: clarify.}.

\section{Justifying the modelling approach}
\epigraph{... But why make models?}{\textit{Derek Zoolander, probably.}}

{\color{red}[Sharon]: ``cette section est très courte. Ne peux-tu pas donner une synthèse historique sur l'utilisation de la modélisation en perception de la parole (ou, su tu veux, perception en général, psychophysique, qu'en sais-je...)''}

In this thesis I will evaluate computational implementations of one-step theories of nonnative speech perception. Notably, I will investigate models from the field of automatic speech recognition (ASR) which are a direct implementation of the Bayesian model shown in equation \ref{eq_onestep1}\footnote{The equivalent of a weighted sampling procedure was preferred over MAP estimation for percept selection, since participant responses in previous experimental work on epenthesis tended to show variation and were not deterministic.}. 
While only the one-step family of theories will be evaluated in this work, I encourage further research to be done with similar methodologies in order to investigate all of the various co-existing proposals.

Indeed, using computational models in order to investigate competing theories is beneficial in several ways. Firstly, the need to translate the theories into model implementations forces model ideators to provide a mathematically and/or algorithmically well defined model. This is in contrast to more vague and ambiguous verbally defined theories that leave more space to reader interpretations. Having more rigorous model definitions also allows for a better understand competing theories (what is the exact nature of the input? which grammar constraints are applied and how? ...), meaning that it is easier to compare proposals and see where they differ significantly or not. 

Secondly, obtaining a computational implementation of a theory means that it is then possible to derive predictions from the models in question. It is then possible to qualitatively and quantitatively examine these predictions, and compare them to what is observed in behavioural data.

\section{Outline of this thesis}
%%%%%%%

{\color{red}[TO-DO while writing discussion]}



