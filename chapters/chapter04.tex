%%%%%%%%%%
% [TODO] %
%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%
% Chapter mini-intro %
%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%% Short BG


%%% Research question + alternatives


%%% Plan


%%%%%%%%%%%%%%%%%%%%%%%%%%
% Articulatory Inversion % %
%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Articulatory Inversion}
\small{\textit{{\color{red}ADD ACKNOWLEDGEMENTS PAUL + EWAN + EMMANUEL.\\}}}

\subsection{Methods}
\subsubsection{Corpora}
\paragraph{MOCHA-TIMIT}
\begin{itemize}
\item General description (type of speech, number of speakers)
\item Articulators
\item Phone set
\item Train-test division (n utterances, time)
\item ...
\end{itemize}

\paragraph{mngu0}
\begin{itemize}
\item General description (type of speech, number of speakers)
\item Articulators: tongue {tip, back, dorsum}, upper lip, lower lip, jaw
\item Phone set
\item Train-test division (n utterances, time)
\item ...
\end{itemize}

\paragraph{mspka}
\begin{itemize}
\item General description (type of speech, number of speakers)
\item Articulators: tongue {tip, back, dorsum}, upper lip, lower lip, jaw
\item Phone set
\item Train-test division (n utterances, time)
\item ...
\end{itemize}

\subsubsection{Features} 
\paragraph{Acoustic}
13 MFCC (c0, not log-energy) + 3 pitch (?) + delta + delta-delta
\paragraph{Articulatory}
{\color{red}Added velum to mngu0 from MOCHA-TIMIT speaker X; added voicing as binary variable...}


\subsubsection{Model architectures} 
\paragraph{Multilayer Perceptron (MLP)}
\paragraph{Mixture Density Network (MDN)}
\paragraph{Trajectory Mixture Density Network (TMDN)}
\paragraph{Recurrent Neural Network (RNN)}

\subsection{Results}
\subsubsection{Selecting model architecture}
{\color{red}Performance is better for RNN blabla when training/testing on mngu0 (?)...}

\subsubsection{Differences in contrast preservation between acoustics and articulatory features}
{\color{red}ABX is higher for X contrast for acoustic, blablabla...}

\subsubsection{Robustness across languages}
{\color{red}Test mspka?}
\subsection{Discussion}

BLABLA


%%%%%%%%%%%%%%%%%%%%%%%%% 
% Predicting confusions % %
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Predicting confusion patterns}
\small{\textit{{\color{red}ADD ACKNOWLEDGEMENTS PAUL + EWAN + EMMANUEL + ACKN MILICA.\\}}}

\subsection{Methods}
\subsubsection{Stimuli}
%We used the same stimuli as in sections \ref{2-parlato} and \ref{2-parlato-dur}. As a reminder, a native French speaker recorded 54 items with the structure $V_{1}C_{1}C_{2}V_{2}$, with $V_{1}$ and $V_{2}$ vowels from the set \{/a/, /i/, /u/\}, and $C_{1}C_{2}$ a cluster from the set \{/bg/, /bn/, /db/, /dg/, /gb/, /gn/\} (e.g. /abgi/).

\subsubsection{Language models}
Item-specific language models were constructed, as shown in Figure \ref{fig:blabla}. Thus, when decoding a $C_{1}C_{2}V_{1}C_{3}V_{2}$ stimulus, the perception model was only given the possibility to transcribe it as $C_{1}(V_{ep})C_{2}V_{1}C_{3}V_{2}$, where phones between parentheses are optional and $V_{ep} = $ \textipa{[@]}. 

We test {\color{red}X} types of language models (LM) when decoding our items; these differ only in the weights given to edges between nodes {\color{red}X and X} in the graph shown in Figure \ref{fig:blabla}: 
\begin{enumerate}
    \item A null language model (\textsc{0P-LM}), which implies that listeners base their decoding of consonant clusters on phonetics alone, without using information on phonotactics.
    \item A phone-unigram language model (\textsc{1P-LM}), which implies that listeners do not take neighbouring phonemes into consideration when decoding the consonant clusters; only the frequency of the vowel $V_{ep}$ to be epenthesized (compared to that of $C_{2}$) is taken into account when choosing epenthetic vowel quality.
    \item An online phone-bigram language model (\textsc{2PO-LM}), which implies that listeners decode the clusters as they hear them (decoding is done from the start of the item). Here the choice of epenthetic vowel is modulated by $C_{1}V_{ep}$ and $C_{1}C_{2}$ diphone frequencies. 
    \item A retro phone-bigram language model (\textsc{2PR-LM}), which implies that listeners decode the clusters based on the most recent information (decoding is done from the end of the item). Here the choice of epenthetic vowel is modulated by $V_{ep}C_{2}$ and $C_{1}C_{2}$ diphone frequencies.
    \item A batch phone-bigram language model (\textsc{2PB-LM}), which implies that listeners decode the item considering the entire structure, with bigrams. Here the choice of epenthetic vowel is modulated by $C_{1}V_{ep}$ and $V_{ep}C_{2}$ (and $C_{1}C_{2}$) diphone frequencies.  
    \item {\color{red}SYLLABLE LM}
\end{enumerate}
{\color{red}The above are copied from another chapter; not all relevant. Maybe. Blabla}

%\begin{figure}[htb]
%\centering
%\includegraphics[width=0.8\linewidth]{chapter04/blabla.pdf}
%\caption{Constrained language model used to test the models (here: LM for \textipa{/znapa/} trials). Nodes in the graph represent states, weighted edges represent transitions between states (here: phonemes). When relevant, eighted edges are labeled with the probability to choose that edge when decoding, which affects the final language model score of each possible path. These scores are then combined with acoustic scores when decoding experimental items. An optional silence can be inserted by the model between states 3 and 4.}
%\label{fig:blabla}
%\end{figure}

\subsubsection{Identification task simulation}
After decoding the stimuli, we obtained for each possible transcription of each item the corresponding acoustic and language model scores. From these we derived the item posteriorgrams, which indicate how probable a given transcription was given the audio input. We used these probabilities as proxies of the probability that a listener might exploit when performing reverse inference during speech perception, and therefore, the probabilities used when responding in an identification task. 

As such, for each item, we obtained a six-dimensional vector $ident_{model} = [p_{none}, p_{a}, p_{e}, p_{i}, p_{o}, p_{u}]$, containing a discrete probability distribution, with a probability mass function linking the identification task options 'none', 'a', 'e', 'i', 'o', 'u', to their respective probabilities (i.e., posteriorgrams).

%%%%%%%%%%%%%%%%%%%%%%%%% 
% Perceptual experiment % %
%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Perceptual experiment}
\small{\textit{{\color{red}ADD ACKNOWLEDGEMENTS PAUL + EWAN + EMMANUEL.\\}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Chapter mini-discussion %
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
%%% Summary

%%% Short discussion

%%% Limitations

%%% Conclusions